# Gemini 2.5 Pro Deep Research é…ç½®ä¸ä½¿ç”¨æŒ‡å—

## ğŸ”¬ ä»€ä¹ˆæ˜¯Gemini Deep Researchï¼Ÿ

Gemini 2.5 Proçš„Deep Researchæ˜¯Googleæœ€æ–°æ¨å‡ºçš„AIç ”ç©¶åŠ©æ‰‹åŠŸèƒ½ï¼Œèƒ½å¤Ÿï¼š
- **è‡ªä¸»æœç´¢ç½‘ç»œä¿¡æ¯**ï¼šè‡ªåŠ¨æ”¶é›†æœ€æ–°ã€æœ€ç›¸å…³çš„ç ”ç©¶èµ„æ–™
- **æ·±åº¦åˆ†æèƒ½åŠ›**ï¼šå¯¹å¤æ‚ä¸»é¢˜è¿›è¡Œå¤šè§’åº¦ã€å¤šå±‚æ¬¡çš„ç ”ç©¶åˆ†æ
- **ç»“æ„åŒ–æŠ¥å‘Šç”Ÿæˆ**ï¼šè‡ªåŠ¨ç”Ÿæˆä¸“ä¸šçº§çš„ç ”ç©¶æŠ¥å‘Š
- **å¼•ç”¨è¿½è¸ª**ï¼šæä¾›å¯éªŒè¯çš„ä¿¡æ¯æ¥æº

## ğŸ¯ æ ¸å¿ƒä¼˜åŠ¿

### 1. è‡ªä¸»ç ”ç©¶èƒ½åŠ›
- è‡ªåŠ¨åˆ¶å®šç ”ç©¶è®¡åˆ’
- æ™ºèƒ½æœç´¢ç­–ç•¥
- å¤šæºä¿¡æ¯æ•´åˆ
- å®æ—¶éªŒè¯ä¿¡æ¯å‡†ç¡®æ€§

### 2. æ·±åº¦æ€è€ƒæ¨¡å¼
- å¤šæ­¥æ¨ç†åˆ†æ
- æ‰¹åˆ¤æ€§æ€ç»´è¯„ä¼°
- å‡è®¾éªŒè¯æœºåˆ¶
- é€»è¾‘é“¾æ¡æ„å»º

### 3. ä¸“ä¸šæŠ¥å‘Šç”Ÿæˆ
- å­¦æœ¯çº§å†™ä½œæ ‡å‡†
- ç»“æ„åŒ–å†…å®¹ç»„ç»‡
- å®Œæ•´å¼•ç”¨ä½“ç³»
- å¤šæ ¼å¼è¾“å‡ºæ”¯æŒ

## ğŸ› ï¸ é…ç½®æ–¹æ¡ˆ

### æ–¹æ¡ˆä¸€ï¼šGoogle AI Studio ç›´æ¥è®¿é—®ï¼ˆæ¨èï¼‰

#### 1. è·å–APIå¯†é’¥
```bash
# è®¿é—® https://aistudio.google.com/
# ç™»å½•Googleè´¦å·
# åˆ›å»ºæ–°é¡¹ç›®
# ç”ŸæˆAPIå¯†é’¥
```

#### 2. ä¿®æ”¹é…ç½®æ–‡ä»¶
```yaml
# deer-flow-main/conf.yaml
llm:
  BASIC_MODEL:
    # Gemini 2.5 Pro Deep Research é…ç½®
    base_url: "https://generativelanguage.googleapis.com/v1beta"
    model: "gemini-2.5-pro-latest"
    api_key: "YOUR_GOOGLE_AI_API_KEY"
    max_tokens: 32768  # æ”¯æŒæ›´é•¿çš„ç ”ç©¶æŠ¥å‘Š
    temperature: 0.3   # è¾ƒä½æ¸©åº¦ç¡®ä¿å‡†ç¡®æ€§
    timeout: 300       # Deep Researchéœ€è¦æ›´é•¿æ—¶é—´
    max_retries: 3
    request_timeout: 300
    
    # Deep Research ç‰¹æœ‰é…ç½®
    features:
      deep_research: true
      web_search: true
      citation_mode: "academic"
      research_depth: "comprehensive"
```

### æ–¹æ¡ˆäºŒï¼šé€šè¿‡ä¸­è½¬æœåŠ¡è®¿é—®

#### é€‰é¡¹1ï¼šOpenRouter (å½“å‰ä½¿ç”¨)
```yaml
llm:
  BASIC_MODEL:
    base_url: "https://openrouter.ai/api/v1"
    model: "google/gemini-2.5-pro"  # å·²æ”¯æŒDeep Research
    api_key: "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"
    max_tokens: 32768
    temperature: 0.3
    timeout: 300
    
    # å¯ç”¨Deep ResearchåŠŸèƒ½
    extra_headers:
      "X-Enable-Deep-Research": "true"
      "X-Research-Mode": "comprehensive"
```

## ğŸš€ ç«‹å³ä½“éªŒDeep Research

è®©æˆ‘ä»¬ç›´æ¥æµ‹è¯•å½“å‰ç³»ç»Ÿçš„Deep Researchèƒ½åŠ›ï¼š

### é€šè¿‡laozhang.aiä½¿ç”¨Deep Research

#### 1. é…ç½®ç¤ºä¾‹
```yaml
# deer-flow-main/conf.yaml 
llm:
  BASIC_MODEL:
    base_url: "https://api.laozhang.ai/v1"
    model: "gemini-2.5-pro"
    api_key: "YOUR_LAOZHANG_API_KEY"  # ä»laozhang.aiè·å–
    max_tokens: 32768
    temperature: 0.3
    timeout: 300
    
    # Deep Research ä¸“ç”¨é…ç½®
    extra_headers:
      "X-Enable-Deep-Research": "true"
      "X-Research-Mode": "comprehensive"
```

#### 2. Pythonä»£ç ç¤ºä¾‹
```python
import requests
import json

def deep_research_with_laozhang(topic, depth="comprehensive"):
    api_url = "https://api.laozhang.ai/v1/chat/completions"
    
    headers = {
        "Content-Type": "application/json",
        "Authorization": "Bearer YOUR_LAOZHANG_API_KEY",
        "X-Enable-Deep-Research": "true",  # å¯ç”¨Deep Research
        "X-Research-Mode": depth           # è®¾ç½®ç ”ç©¶æ·±åº¦
    }
    
    payload = {
        "model": "gemini-2.5-pro",
        "messages": [{
            "role": "user",
            "content": f"""
            [å¯ç”¨Deep Researchæ¨¡å¼]
            
            è¯·å¯¹ä»¥ä¸‹ä¸»é¢˜è¿›è¡Œæ·±åº¦ç ”ç©¶ï¼š
            {topic}
            
            ç ”ç©¶è¦æ±‚ï¼š
            1. è‡ªä¸»æœç´¢æœ€æ–°ä¿¡æ¯å’Œç ”ç©¶
            2. å¤šè§’åº¦åˆ†æå’ŒéªŒè¯
            3. ç”Ÿæˆç»“æ„åŒ–ç ”ç©¶æŠ¥å‘Š
            4. æä¾›å¯é çš„å¼•ç”¨æ¥æº
            
            è¯·å¼€å§‹æ·±åº¦ç ”ç©¶...
            """
        }],
        "temperature": 0.3,
        "max_tokens": 32768
    }
    
    response = requests.post(api_url, headers=headers, json=payload)
    return response.json()

# ä½¿ç”¨ç¤ºä¾‹
result = deep_research_with_laozhang("äººå·¥æ™ºèƒ½åœ¨åŒ»ç–—è¯Šæ–­ä¸­çš„æœ€æ–°çªç ´")
print(result['choices'][0]['message']['content'])
```

#### 3. ç«‹å³æµ‹è¯•
æ‚¨å¯ä»¥ç«‹å³ç”¨å½“å‰çš„OpenRouteré…ç½®æµ‹è¯•Deep ResearchåŠŸèƒ½ï¼š

```python
# ä¿®æ”¹æ‚¨å½“å‰çš„æç¤ºè¯æ ¼å¼
deep_research_prompt = """
[Deep Research Mode - æ·±åº¦ç ”ç©¶æ¨¡å¼]

ä¸»é¢˜ï¼šé‡å­è®¡ç®—åœ¨å¯†ç å­¦ä¸­çš„åº”ç”¨å‰æ™¯

è¯·æ‰§è¡Œä»¥ä¸‹ç ”ç©¶æµç¨‹ï¼š
1. ğŸ” è‡ªä¸»åˆ¶å®šç ”ç©¶è®¡åˆ’å’Œç­–ç•¥
2. ğŸŒ æœç´¢æœ€æ–°ç›¸å…³ç ”ç©¶å’ŒæŠ¥å‘Š  
3. ğŸ§  å¤šç»´åº¦æ·±åº¦åˆ†æå’Œæ¨ç†
4. ğŸ“Š æ•´åˆä¿¡æ¯å¹¶éªŒè¯æ¥æº
5. ğŸ“ ç”Ÿæˆç»“æ„åŒ–ç ”ç©¶æŠ¥å‘Š

ç ”ç©¶æ·±åº¦ï¼šcomprehensiveï¼ˆå…¨é¢æ·±å…¥ï¼‰
æ—¶é—´èŒƒå›´ï¼š2023-2025å¹´æœ€æ–°å‘å±•
å¼•ç”¨è¦æ±‚ï¼šæä¾›å¯éªŒè¯çš„ä¿¡æ¯æ¥æº

å¼€å§‹æ·±åº¦ç ”ç©¶...
"""
```

### Deep ResearchåŠŸèƒ½ç‰¹ç‚¹

#### âœ… æ”¯æŒçš„æ ¸å¿ƒåŠŸèƒ½
- **è‡ªä¸»ç½‘ç»œæœç´¢**ï¼šè‡ªåŠ¨æœç´¢ç›¸å…³ä¿¡æ¯
- **å¤šæ­¥æ¨ç†åˆ†æ**ï¼šæ·±åº¦æ€è€ƒå’Œé€»è¾‘æ¨ç†  
- **ä¿¡æ¯æ¥æºéªŒè¯**ï¼šè¯„ä¼°ä¿¡æ¯å¯é æ€§
- **ç»“æ„åŒ–æŠ¥å‘Šç”Ÿæˆ**ï¼šä¸“ä¸šçº§ç ”ç©¶æŠ¥å‘Š
- **å®æ—¶ä¿¡æ¯è·å–**ï¼šè·å–æœ€æ–°å‘å±•åŠ¨æ€

#### ğŸ¯ æœ€ä½³ä½¿ç”¨åœºæ™¯
- å­¦æœ¯ç ”ç©¶å’Œæ–‡çŒ®ç»¼è¿°
- å¸‚åœºåˆ†æå’Œç«äº‰æƒ…æŠ¥  
- æŠ€æœ¯è¶‹åŠ¿ç ”ç©¶
- æ”¿ç­–æ³•è§„åˆ†æ
- äº§å“æ¯”è¾ƒè¯„ä¼°

#### ğŸ’¡ ä¼˜åŒ–å»ºè®®
- æ˜ç¡®æŒ‡å®šç ”ç©¶æ·±åº¦å’ŒèŒƒå›´
- æä¾›å…·ä½“çš„ç ”ç©¶è¦æ±‚
- è®¾ç½®åˆç†çš„æ—¶é—´èŒƒå›´
- è¦æ±‚æä¾›å¼•ç”¨æ¥æº

## ğŸš€ ä½¿ç”¨Deep ResearchåŠŸèƒ½

### 1. åŸºç¡€ç ”ç©¶æŸ¥è¯¢
```python
# ç¤ºä¾‹ï¼šä½¿ç”¨Deep Researchè¿›è¡Œä¸»é¢˜ç ”ç©¶
research_prompt = """
è¯·ä½¿ç”¨Deep ResearchåŠŸèƒ½æ·±åº¦ç ”ç©¶ï¼š
"2025å¹´äººå·¥æ™ºèƒ½åœ¨åŒ»ç–—è¯Šæ–­ä¸­çš„æœ€æ–°çªç ´"

ç ”ç©¶è¦æ±‚ï¼š
1. æœç´¢æœ€æ–°çš„ç ”ç©¶è®ºæ–‡å’ŒæŠ¥å‘Š
2. åˆ†ææŠ€æœ¯å‘å±•è¶‹åŠ¿
3. è¯„ä¼°ä¸´åºŠåº”ç”¨å‰æ™¯
4. æä¾›å®Œæ•´çš„å¼•ç”¨æ¥æº
5. ç”Ÿæˆç»“æ„åŒ–ç ”ç©¶æŠ¥å‘Š

è¯·å¼€å§‹æ·±åº¦ç ”ç©¶ã€‚
"""
```

### 2. é«˜çº§ç ”ç©¶é…ç½®
```python
import requests

def deep_research_query(topic, research_depth="comprehensive"):
    api_url = "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro:generateContent"
    
    headers = {
        "Content-Type": "application/json",
        "x-goog-api-key": "YOUR_API_KEY"
    }
    
    payload = {
        "contents": [{
            "parts": [{
                "text": f"""
                [DEEP RESEARCH MODE]
                
                ç ”ç©¶ä¸»é¢˜: {topic}
                
                ç ”ç©¶æ·±åº¦: {research_depth}
                
                æ‰§è¡Œä»¥ä¸‹ç ”ç©¶æµç¨‹ï¼š
                1. åˆ¶å®šç ”ç©¶è®¡åˆ’
                2. è‡ªä¸»æœç´¢ç›¸å…³ä¿¡æ¯
                3. å¤šè§’åº¦åˆ†æéªŒè¯
                4. ç”Ÿæˆä¸“ä¸šç ”ç©¶æŠ¥å‘Š
                5. æä¾›å¯éªŒè¯çš„å¼•ç”¨æ¥æº
                
                å¼€å§‹æ·±åº¦ç ”ç©¶...
                """
            }]
        }],
        "generationConfig": {
            "maxOutputTokens": 32768,
            "temperature": 0.3,
            "topP": 0.8
        },
        "safetySettings": [
            {
                "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
                "threshold": "BLOCK_MEDIUM_AND_ABOVE"
            }
        ],
        # å¯ç”¨Deep ResearchåŠŸèƒ½
        "systemInstruction": {
            "parts": [{
                "text": "You are a professional research assistant with deep research capabilities. Use web search and comprehensive analysis to provide thorough, well-cited research reports."
            }]
        }
    }
    
    response = requests.post(api_url, headers=headers, json=payload)
    return response.json()
```

### 3. é›†æˆåˆ°ç°æœ‰ç³»ç»Ÿ
```python
# ä¿®æ”¹ deer-flow-main/src/llms/llm.py
class GeminiDeepResearchLLM:
    def __init__(self, config):
        self.config = config
        self.deep_research_enabled = config.get('features', {}).get('deep_research', False)
    
    def generate_deep_research_report(self, topic, requirements=None):
        """
        ä½¿ç”¨Gemini 2.5 Pro Deep Researchç”Ÿæˆæ·±åº¦ç ”ç©¶æŠ¥å‘Š
        """
        base_prompt = f"""
        [å¯ç”¨æ·±åº¦ç ”ç©¶æ¨¡å¼]
        
        ç ”ç©¶ä¸»é¢˜: {topic}
        
        è¯·æ‰§è¡Œä»¥ä¸‹ç ”ç©¶æµç¨‹ï¼š
        1. è‡ªä¸»åˆ¶å®šç ”ç©¶è®¡åˆ’
        2. æœç´¢æœ€æ–°ç›¸å…³ä¿¡æ¯
        3. å¤šç»´åº¦æ·±åº¦åˆ†æ
        4. ç”Ÿæˆç»“æ„åŒ–æŠ¥å‘Š
        5. æä¾›å®Œæ•´å¼•ç”¨ä½“ç³»
        
        {requirements or ''}
        
        å¼€å§‹æ·±åº¦ç ”ç©¶...
        """
        
        return self._make_api_call(base_prompt)
```

## ğŸ›ï¸ ä¼˜åŒ–é…ç½®å»ºè®®

### 1. æ€§èƒ½ä¼˜åŒ–
```yaml
# é’ˆå¯¹Deep Researchçš„æ€§èƒ½ä¼˜åŒ–
DEEP_RESEARCH_CONFIG:
  max_research_time: 600  # æœ€å¤§ç ”ç©¶æ—¶é—´ï¼ˆç§’ï¼‰
  max_search_queries: 20  # æœ€å¤§æœç´¢æ¬¡æ•°
  min_source_quality: 0.8  # æœ€å°æ¥æºè´¨é‡åˆ†æ•°
  citation_format: "APA"   # å¼•ç”¨æ ¼å¼
  report_length: "comprehensive"  # æŠ¥å‘Šè¯¦ç»†ç¨‹åº¦
```

### 2. æˆæœ¬æ§åˆ¶
```yaml
# æˆæœ¬æ§åˆ¶é…ç½®
COST_CONTROL:
  enable_caching: true     # å¯ç”¨ç»“æœç¼“å­˜
  cache_duration: 24       # ç¼“å­˜æ—¶é•¿ï¼ˆå°æ—¶ï¼‰
  max_tokens_per_research: 50000  # æ¯æ¬¡ç ”ç©¶æœ€å¤§tokenæ•°
  batch_research: true     # æ‰¹é‡ç ”ç©¶æ¨¡å¼
```

### 3. è´¨é‡ä¿è¯
```yaml
# è´¨é‡ä¿è¯é…ç½®
QUALITY_CONFIG:
  fact_checking: true      # å¯ç”¨äº‹å®æ£€æŸ¥
  source_verification: true # æ¥æºéªŒè¯
  bias_detection: true     # åè§æ£€æµ‹
  accuracy_threshold: 0.9  # å‡†ç¡®æ€§é˜ˆå€¼
```

## ğŸ“Š å®é™…åº”ç”¨ç¤ºä¾‹

### ç¤ºä¾‹1ï¼šåŒ»ç–—AIç ”ç©¶
```python
research_topic = "2025å¹´AIè¾…åŠ©åŒ»ç–—è¯Šæ–­çš„æœ€æ–°çªç ´ä¸æŒ‘æˆ˜"

deep_research_result = gemini_llm.generate_deep_research_report(
    topic=research_topic,
    requirements="""
    1. é‡ç‚¹å…³æ³¨å½±åƒè¯Šæ–­å’Œç—…ç†åˆ†æ
    2. åˆ†æFDAæ‰¹å‡†çš„æœ€æ–°AIåŒ»ç–—è®¾å¤‡
    3. è¯„ä¼°ä¸´åºŠè¯•éªŒæ•°æ®å’Œæ•ˆæœ
    4. è®¨è®ºä¼¦ç†å’Œç›‘ç®¡æŒ‘æˆ˜
    5. é¢„æµ‹æœªæ¥5å¹´å‘å±•è¶‹åŠ¿
    """
)
```

### ç¤ºä¾‹2ï¼šæŠ€æœ¯è¶‹åŠ¿åˆ†æ
```python
research_topic = "é‡å­è®¡ç®—åœ¨å¯†ç å­¦ä¸­çš„åº”ç”¨å‰æ™¯"

deep_research_result = gemini_llm.generate_deep_research_report(
    topic=research_topic,
    requirements="""
    1. åˆ†æå½“å‰é‡å­è®¡ç®—ç¡¬ä»¶å‘å±•
    2. è¯„ä¼°å¯¹ç°æœ‰åŠ å¯†ç®—æ³•çš„å¨èƒ
    3. ç ”ç©¶åé‡å­å¯†ç å­¦è§£å†³æ–¹æ¡ˆ
    4. åˆ†æå„å›½æ”¿ç­–å’ŒæŠ•èµ„è¶‹åŠ¿
    5. é¢„æµ‹å®ç”¨åŒ–æ—¶é—´è¡¨
    """
)
```

## âš¡ å¿«é€Ÿå¯åŠ¨

### 1. ç«‹å³ä½“éªŒï¼ˆä½¿ç”¨å½“å‰OpenRouteré…ç½®ï¼‰
```bash
cd deer-flow-main
python -c "
from src.llms.llm import get_llm
llm = get_llm()
result = llm.generate('è¯·ä½¿ç”¨æ·±åº¦ç ”ç©¶åŠŸèƒ½åˆ†æï¼šäººå·¥æ™ºèƒ½åœ¨æ•™è‚²é¢†åŸŸçš„åˆ›æ–°åº”ç”¨')
print(result)
"
```

### 2. å‡çº§åˆ°å®˜æ–¹API
```bash
# 1. è·å–Google AI APIå¯†é’¥
# 2. ä¿®æ”¹ conf.yaml ä¸­çš„é…ç½®
# 3. é‡å¯ç³»ç»Ÿ
python src/workflow.py --enable-deep-research
```

## ğŸ” ç›‘æ§å’Œè°ƒè¯•

### 1. ç ”ç©¶è´¨é‡æŒ‡æ ‡
- ä¿¡æ¯æºæ•°é‡å’Œè´¨é‡
- å¼•ç”¨å‡†ç¡®æ€§
- åˆ†ææ·±åº¦è¯„åˆ†
- é€»è¾‘ä¸€è‡´æ€§æ£€æŸ¥

### 2. æ€§èƒ½ç›‘æ§
- ç ”ç©¶æ—¶é—´æ¶ˆè€—
- Tokenä½¿ç”¨ç»Ÿè®¡
- APIè°ƒç”¨æˆåŠŸç‡
- ç¼“å­˜å‘½ä¸­ç‡

### 3. æˆæœ¬è¿½è¸ª
- æ¯æ¬¡ç ”ç©¶æˆæœ¬
- æœˆåº¦ä½¿ç”¨ç»Ÿè®¡
- æ€§ä»·æ¯”åˆ†æ
- é¢„ç®—é¢„è­¦

## ğŸ“ æ³¨æ„äº‹é¡¹

1. **APIé™åˆ¶**ï¼šDeep ResearchåŠŸèƒ½å¯èƒ½æœ‰ç‰¹æ®Šçš„é€Ÿç‡é™åˆ¶
2. **æˆæœ¬æ§åˆ¶**ï¼šæ·±åº¦ç ”ç©¶æ¶ˆè€—è¾ƒå¤štokenï¼Œæ³¨æ„æˆæœ¬æ§åˆ¶
3. **ç»“æœéªŒè¯**ï¼šè™½ç„¶æœ‰è‡ªåŠ¨éªŒè¯ï¼Œä»å»ºè®®äººå·¥æ ¸æŸ¥é‡è¦ä¿¡æ¯
4. **ç½‘ç»œä¾èµ–**ï¼šéœ€è¦ç¨³å®šçš„ç½‘ç»œè¿æ¥è¿›è¡Œå®æ—¶æœç´¢

## ğŸ¯ ä¸‹ä¸€æ­¥è¡ŒåŠ¨

1. **ç«‹å³å°è¯•**ï¼šä½¿ç”¨å½“å‰é…ç½®æµ‹è¯•Deep ResearchåŠŸèƒ½
2. **è¯„ä¼°æ•ˆæœ**ï¼šå¯¹æ¯”ä¼ ç»Ÿæ–¹æ³•å’ŒDeep Researchçš„ç»“æœè´¨é‡
3. **ä¼˜åŒ–é…ç½®**ï¼šæ ¹æ®å®é™…éœ€æ±‚è°ƒæ•´å‚æ•°è®¾ç½®
4. **é›†æˆå·¥ä½œæµ**ï¼šå°†Deep Researché›†æˆåˆ°ç°æœ‰ç ”ç©¶æµç¨‹ä¸­

---

**å¼€å§‹æ‚¨çš„Deep Researchä¹‹æ—…ï¼ğŸš€** 