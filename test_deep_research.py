#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
OpenRouter Deep Research åŠŸèƒ½æµ‹è¯•
"""

import sys
sys.path.append('src')

def test_deep_research_simple():
    """ç®€å•æµ‹è¯• Deep Research åŠŸèƒ½"""
    
    try:
        from llms.llm import get_llm_by_type
        
        print("ğŸ”¬ æµ‹è¯• OpenRouter Gemini 2.5 Pro Deep Research")
        print("=" * 50)
        
        # è·å–BASIC_MODELç±»å‹çš„LLMå®ä¾‹ï¼ˆå¯¹åº”OpenRouteré…ç½®ï¼‰
        llm = get_llm_by_type("BASIC_MODEL")
        
        # ç®€å•çš„Deep Researchæµ‹è¯•
        prompt = """
[Deep Research Mode]

è¯·å¯¹"2025å¹´äººå·¥æ™ºèƒ½å‘å±•è¶‹åŠ¿"è¿›è¡Œæ·±åº¦ç ”ç©¶ï¼š

1. åˆ†ææŠ€æœ¯çªç ´ç‚¹
2. è¯„ä¼°å•†ä¸šåº”ç”¨å‰æ™¯  
3. è¯†åˆ«æ½œåœ¨é£é™©
4. é¢„æµ‹å‘å±•æ–¹å‘

è¯·å±•ç¤ºæ€è€ƒè¿‡ç¨‹å¹¶ç”Ÿæˆç»“æ„åŒ–æŠ¥å‘Šã€‚
"""
        
        print("ğŸ¤” æ­£åœ¨æ‰§è¡Œæ·±åº¦ç ”ç©¶...")
        
        # ä½¿ç”¨invokeæ–¹æ³•è°ƒç”¨æ¨¡å‹
        from langchain.schema import HumanMessage
        messages = [HumanMessage(content=prompt)]
        result = llm.invoke(messages)
        
        print("âœ… ç ”ç©¶å®Œæˆï¼")
        print("ğŸ“ æŠ¥å‘Šé¢„è§ˆï¼š")
        print("-" * 50)
        
        # æå–ç»“æœå†…å®¹
        content = result.content if hasattr(result, 'content') else str(result)
        print(content[:800] + "..." if len(content) > 800 else content)
        
    except Exception as e:
        print(f"âŒ é”™è¯¯ï¼š{e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_deep_research_simple() 