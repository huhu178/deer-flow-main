#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤šæ¨¡å‹ç ”ç©¶ç³»ç»Ÿå¯åŠ¨è„šæœ¬ - é›†æˆç‰ˆ
ä½¿ç”¨srcé¡¹ç›®çš„å®Œæ•´å·¥ä½œæµï¼Œæ”¯æŒå¤šæ¨¡å‹å¹¶è¡ŒæŠ¥å‘Šç”Ÿæˆ
"""

import asyncio
import logging
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
current_dir = Path(__file__).parent.parent
if str(current_dir) not in sys.path:
    sys.path.insert(0, str(current_dir))

from src.workflow import run_agent_workflow_async
from src.utils.multi_model_manager import MultiModelManager

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


async def run_integrated_multi_model_research(
    query: str, 
    enable_multi_model: bool = True,
    max_plan_iterations: int = 2,
    max_step_num: int = 5
):
    """
    è¿è¡Œé›†æˆçš„å¤šæ¨¡å‹ç ”ç©¶
    
    Args:
        query: ç ”ç©¶æŸ¥è¯¢
        enable_multi_model: æ˜¯å¦å¯ç”¨å¤šæ¨¡å‹æŠ¥å‘Šç”Ÿæˆ
        max_plan_iterations: æœ€å¤§è®¡åˆ’è¿­ä»£æ¬¡æ•°
        max_step_num: æœ€å¤§æ­¥éª¤æ•°
    """
    print(f"ğŸš€ å¯åŠ¨é›†æˆå¤šæ¨¡å‹ç ”ç©¶ç³»ç»Ÿ")
    print(f"ğŸ“ ç ”ç©¶æŸ¥è¯¢: {query[:100]}...")
    print(f"ğŸ”§ å¤šæ¨¡å‹æ¨¡å¼: {'å¯ç”¨' if enable_multi_model else 'ç¦ç”¨'}")
    print(f"âš™ï¸ æœ€å¤§è®¡åˆ’è¿­ä»£: {max_plan_iterations}")
    print(f"ğŸ“Š æœ€å¤§æ­¥éª¤æ•°: {max_step_num}")
    print("=" * 80)
    
    try:
        # è¿è¡Œå®Œæ•´çš„å·¥ä½œæµ
        final_state = await run_agent_workflow_async(
            user_input=query,
            debug=False,
            max_plan_iterations=max_plan_iterations,
            max_step_num=max_step_num,
            enable_background_investigation=True,
            enable_multi_model_report=enable_multi_model,
            locale="zh-CN"
        )
        
        print("\nâœ… ç ”ç©¶ä»»åŠ¡å®Œæˆï¼")
        
        # è¾“å‡ºç»“æœæ‘˜è¦
        if "final_report" in final_state:
            print("\nğŸ“Š ç”Ÿæˆçš„æŠ¥å‘Š:")
            print("=" * 80)
            print(final_state["final_report"][:1500])  # æ˜¾ç¤ºå‰1500å­—ç¬¦
            if len(final_state["final_report"]) > 1500:
                print("...\n(æŠ¥å‘Šå†…å®¹è¾ƒé•¿ï¼Œå·²æˆªæ–­æ˜¾ç¤º)")
            print("=" * 80)
        
        # å¦‚æœæœ‰å¤šæ¨¡å‹ç»“æœï¼Œæ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
        if "multi_model_results" in final_state:
            results = final_state["multi_model_results"]
            print(f"\nğŸ¯ å¤šæ¨¡å‹ç”Ÿæˆç»Ÿè®¡:")
            print(f"- å‚ä¸æ¨¡å‹: {results['summary']['total_models']}")
            print(f"- æˆåŠŸç”Ÿæˆ: {results['summary']['successful_reports']}")
            print(f"- æ€»è€—æ—¶: {results['summary']['total_execution_time']:.2f}ç§’")
            
            print(f"\nğŸ“ ä¿å­˜çš„æ–‡ä»¶:")
            if "saved_files" in final_state:
                for file_type, filepath in final_state["saved_files"].items():
                    print(f"- {file_type}: {filepath}")
        
        return final_state
        
    except Exception as e:
        print(f"âŒ ç ”ç©¶ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
        logger.error(f"å·¥ä½œæµæ‰§è¡Œé”™è¯¯: {e}")
        raise


async def demo_13_dimension_research():
    """
    æ¼”ç¤º13ç»´åº¦è°ƒç ”æ¡†æ¶çš„å¤šæ¨¡å‹ç ”ç©¶
    """
    print("ğŸ¯ 13ç»´åº¦è°ƒç ”æ¡†æ¶å¤šæ¨¡å‹æ¼”ç¤º")
    print("=" * 80)
    
    # 13ç»´åº¦è°ƒç ”æŸ¥è¯¢
    query = """
è¯·åŸºäº13ç»´åº¦è°ƒç ”æ¡†æ¶ï¼Œå¯¹"åŸºäºDXAå½±åƒAIç‰¹å¾çš„éª¨-å¿ƒè¡€ç®¡è½´ç ”ç©¶"è¿›è¡Œå…¨é¢åˆ†æã€‚

è¯·é‡ç‚¹å…³æ³¨ä»¥ä¸‹13ä¸ªç»´åº¦ï¼š

1. **é‡è¦çš„ä¸´åºŠé—®é¢˜**: å½“å‰éª¨-å¿ƒè¡€ç®¡ç–¾ç—…è¯Šæ–­å’Œæ²»ç–—é¢ä¸´çš„ä¸»è¦æŒ‘æˆ˜
2. **é‡è¦çš„ç§‘å­¦é—®é¢˜**: AIæŠ€æœ¯åœ¨DXAå½±åƒåˆ†æä¸­çš„æ ¸å¿ƒç§‘å­¦é—®é¢˜
3. **è¿‘ä¸‰å¹´ç§‘å­¦è¿›å±•**: 2022-2024å¹´éª¨-å¿ƒè¡€ç®¡è½´ç ”ç©¶çš„é‡è¦çªç ´
4. **äº¤å‰å­¦ç§‘æœºä¼š**: AIã€åŒ»å­¦å½±åƒã€å¿ƒè¡€ç®¡å­¦ã€éª¨ç§‘å­¦çš„èåˆæœºä¼š
5. **æ–¹æ³•å­¦åˆ›æ–°**: æ–°çš„ç®—æ³•ã€æ¨¡å‹æ¶æ„å’Œåˆ†ææŠ€æœ¯
6. **ä¸“åˆ©æˆæƒçŠ¶å†µ**: ç›¸å…³æŠ€æœ¯çš„çŸ¥è¯†äº§æƒç°çŠ¶å’Œè¶‹åŠ¿
7. **å›½é™…åˆä½œæœºä¼š**: å…¨çƒèŒƒå›´å†…çš„åˆä½œç ”ç©¶æœºä¼šå’Œå¹³å°
8. **ç§‘ç ”èµ„é‡‘æ”¯æŒ**: æ”¿åºœå’Œä¼ä¸šåœ¨è¯¥é¢†åŸŸçš„èµ„åŠ©æƒ…å†µ
9. **ä¼¦ç†ä¸åˆè§„è¦æ±‚**: åŒ»ç–—AIçš„ä¼¦ç†è§„èŒƒå’Œç›‘ç®¡è¦æ±‚
10. **å¼€æ”¾æ•°æ®èµ„æº**: å¯ç”¨çš„å…¬å¼€æ•°æ®é›†å’Œå…±äº«èµ„æº
11. **å…¬å…±å«ç”Ÿäº‹ä»¶å½±å“**: ç–«æƒ…ç­‰å¯¹è¯¥ç ”ç©¶é¢†åŸŸçš„å½±å“
12. **å›½å®¶æ”¿ç­–ç¯å¢ƒ**: ç›¸å…³æ”¿ç­–æ³•è§„å’Œå‘å±•è§„åˆ’
13. **ç»¼åˆè¯„ä¼°ä¸æœºä¼šè¯†åˆ«**: æœªæ¥å‘å±•æœºé‡ã€æŒ‘æˆ˜å’Œå»ºè®®

è¯·ç”Ÿæˆè¯¦ç»†çš„ç ”ç©¶æŠ¥å‘Šï¼ŒåŒ…æ‹¬ç°çŠ¶åˆ†æã€æŠ€æœ¯è¶‹åŠ¿ã€æŒ‘æˆ˜ä¸æœºé‡ã€å‘å±•å»ºè®®ç­‰å†…å®¹ã€‚
    """
    
    print(f"ğŸ“‹ ç ”ç©¶ä¸»é¢˜: åŸºäºDXAå½±åƒAIç‰¹å¾çš„éª¨-å¿ƒè¡€ç®¡è½´ç ”ç©¶")
    print(f"ğŸ” åˆ†ææ¡†æ¶: 13ç»´åº¦è°ƒç ”æ¡†æ¶")
    print(f"ğŸ¯ ç›®æ ‡: å…¨é¢åˆ†æå’Œè¯„ä¼°")
    print("\n" + "=" * 80)
    
    # è¿è¡Œå¤šæ¨¡å‹ç ”ç©¶
    result = await run_integrated_multi_model_research(
        query=query, 
        enable_multi_model=True,
        max_plan_iterations=2,
        max_step_num=6
    )
    
    return result


async def demo_ai_medical_imaging():
    """
    æ¼”ç¤ºAIåŒ»å­¦å½±åƒåˆ†æçš„å¤šæ¨¡å‹ç ”ç©¶
    """
    print("ğŸ¯ AIåŒ»å­¦å½±åƒåˆ†æå¤šæ¨¡å‹æ¼”ç¤º")
    print("=" * 80)
    
    query = """
è¯·å¯¹äººå·¥æ™ºèƒ½åœ¨åŒ»å­¦å½±åƒåˆ†æé¢†åŸŸçš„åº”ç”¨è¿›è¡Œå…¨é¢ç ”ç©¶åˆ†æã€‚

ç ”ç©¶é‡ç‚¹åŒ…æ‹¬ï¼š
1. æŠ€æœ¯ç°çŠ¶å’Œå‘å±•è¶‹åŠ¿
2. ä¸»è¦åº”ç”¨åœºæ™¯å’ŒæˆåŠŸæ¡ˆä¾‹
3. æŠ€æœ¯æŒ‘æˆ˜å’Œè§£å†³æ–¹æ¡ˆ
4. å¸‚åœºå‰æ™¯å’Œå•†ä¸šåŒ–æœºä¼š
5. ç›‘ç®¡ç¯å¢ƒå’Œä¼¦ç†è€ƒé‡
6. æœªæ¥å‘å±•æ–¹å‘å’Œå»ºè®®

è¯·ç”Ÿæˆä¸“ä¸šçš„ç ”ç©¶æŠ¥å‘Šï¼ŒåŒ…æ‹¬æŠ€æœ¯åˆ†æã€å¸‚åœºåˆ†æã€é£é™©è¯„ä¼°ç­‰å†…å®¹ã€‚
    """
    
    print(f"ğŸ“‹ ç ”ç©¶ä¸»é¢˜: AIåŒ»å­¦å½±åƒåˆ†æ")
    print(f"ğŸ” åˆ†æè§’åº¦: æŠ€æœ¯ã€å¸‚åœºã€ç›‘ç®¡ã€æœªæ¥")
    print(f"ğŸ¯ ç›®æ ‡: å…¨é¢è¯„ä¼°å’Œå»ºè®®")
    print("\n" + "=" * 80)
    
    # è¿è¡Œå¤šæ¨¡å‹ç ”ç©¶
    result = await run_integrated_multi_model_research(
        query=query, 
        enable_multi_model=True,
        max_plan_iterations=2,
        max_step_num=4
    )
    
    return result


async def compare_single_vs_multi_model():
    """
    å¯¹æ¯”å•æ¨¡å‹å’Œå¤šæ¨¡å‹çš„æ•ˆæœ
    """
    print("\nğŸ” å•æ¨¡å‹ vs å¤šæ¨¡å‹å¯¹æ¯”æµ‹è¯•")
    print("=" * 80)
    
    test_query = """
è¯·åˆ†ææ·±åº¦å­¦ä¹ æŠ€æœ¯åœ¨éª¨ç§‘ç–¾ç—…è¯Šæ–­ä¸­çš„åº”ç”¨ç°çŠ¶ï¼ŒåŒ…æ‹¬ï¼š
1. ä¸»è¦æŠ€æœ¯æ–¹æ³•å’Œç®—æ³•
2. ä¸´åºŠåº”ç”¨æ•ˆæœå’Œæ¡ˆä¾‹
3. æŠ€æœ¯æŒ‘æˆ˜å’Œé™åˆ¶
4. å‘å±•å‰æ™¯å’Œå»ºè®®

è¦æ±‚ç”Ÿæˆç®€æ´ä½†å…¨é¢çš„åˆ†ææŠ¥å‘Šã€‚
    """
    
    print("ğŸ”„ è¿è¡Œå•æ¨¡å‹æ¨¡å¼...")
    single_result = await run_integrated_multi_model_research(
        test_query, 
        enable_multi_model=False,
        max_plan_iterations=1,
        max_step_num=3
    )
    
    print("\nğŸ”„ è¿è¡Œå¤šæ¨¡å‹æ¨¡å¼...")
    multi_result = await run_integrated_multi_model_research(
        test_query, 
        enable_multi_model=True,
        max_plan_iterations=1,
        max_step_num=3
    )
    
    print("\nğŸ“Š å¯¹æ¯”ç»“æœ:")
    print(f"- å•æ¨¡å‹æŠ¥å‘Šé•¿åº¦: {len(single_result.get('final_report', ''))}å­—ç¬¦")
    if 'multi_model_results' in multi_result:
        multi_summary = multi_result['multi_model_results']['summary']
        print(f"- å¤šæ¨¡å‹å‚ä¸æ•°é‡: {multi_summary['total_models']}")
        print(f"- å¤šæ¨¡å‹æˆåŠŸæ•°é‡: {multi_summary['successful_reports']}")
        print(f"- å¤šæ¨¡å‹æ€»è€—æ—¶: {multi_summary['total_execution_time']:.2f}ç§’")


def show_system_status():
    """æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€"""
    print("ğŸ”§ ç³»ç»ŸçŠ¶æ€æ£€æŸ¥")
    print("=" * 60)
    
    # æ£€æŸ¥å¤šæ¨¡å‹é…ç½®
    try:
        manager = MultiModelManager()
        manager.show_status()
        
        available_models = manager.get_available_models()
        if available_models:
            print(f"\nâœ… ç³»ç»Ÿå°±ç»ªï¼Œå¯ä½¿ç”¨ {len(available_models)} ä¸ªæ¨¡å‹")
        else:
            print(f"\nâš ï¸ æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹ï¼Œè¯·æ£€æŸ¥é…ç½®")
            
    except Exception as e:
        print(f"\nâŒ ç³»ç»Ÿæ£€æŸ¥å¤±è´¥: {e}")


def main():
    """
    ä¸»å‡½æ•°
    """
    print("ğŸ‰ æ¬¢è¿ä½¿ç”¨deer-flowé›†æˆå¤šæ¨¡å‹ç ”ç©¶ç³»ç»Ÿï¼")
    print("=" * 80)
    
    # æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€
    show_system_status()
    
    print("\né€‰æ‹©è¿è¡Œæ¨¡å¼:")
    print("1. 13ç»´åº¦è°ƒç ”æ¡†æ¶æ¼”ç¤º (æ¨è)")
    print("2. AIåŒ»å­¦å½±åƒåˆ†ææ¼”ç¤º")
    print("3. å•æ¨¡å‹vså¤šæ¨¡å‹å¯¹æ¯”")
    print("4. è‡ªå®šä¹‰ç ”ç©¶æŸ¥è¯¢")
    print("5. ä»…æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€")
    
    try:
        choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1-5): ").strip()
        
        if choice == "1":
            asyncio.run(demo_13_dimension_research())
        elif choice == "2":
            asyncio.run(demo_ai_medical_imaging())
        elif choice == "3":
            asyncio.run(compare_single_vs_multi_model())
        elif choice == "4":
            custom_query = input("è¯·è¾“å…¥æ‚¨çš„ç ”ç©¶æŸ¥è¯¢: ").strip()
            if custom_query:
                enable_multi = input("æ˜¯å¦å¯ç”¨å¤šæ¨¡å‹? (y/n): ").strip().lower() == 'y'
                asyncio.run(run_integrated_multi_model_research(
                    custom_query, 
                    enable_multi_model=enable_multi
                ))
            else:
                print("âŒ æŸ¥è¯¢ä¸èƒ½ä¸ºç©º")
        elif choice == "5":
            print("âœ… ç³»ç»ŸçŠ¶æ€æ£€æŸ¥å®Œæˆ")
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©")
            
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ ç”¨æˆ·å–æ¶ˆæ“ä½œ")
    except Exception as e:
        print(f"\nâŒ æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        logger.error(f"ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")


if __name__ == "__main__":
    main() 