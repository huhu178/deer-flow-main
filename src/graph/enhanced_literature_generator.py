# Copyright (c) 2025 Bytedance Ltd. and/or its affiliates
# SPDX-License-Identifier: MIT

"""
å¢å¼ºæ–‡çŒ®æœç´¢é©±åŠ¨çš„æŠ¥å‘Šç”Ÿæˆå™¨
å°†é«˜è´¨é‡æ–‡çŒ®æœç´¢æ·±åº¦é›†æˆåˆ°ç»¼åˆæŠ¥å‘Šç”Ÿæˆæµç¨‹ä¸­
"""

import logging
import json
import time
from pathlib import Path
from typing import Dict, List, Any, Optional
from datetime import datetime

from src.tools import get_pubmed_search_tool, get_google_scholar_search_tool, get_web_search_tool
from src.tools.enhanced_search_coordinator import EnhancedSearchCoordinator
from src.tools.journal_quality_controller import journal_quality_controller
from src.config.enhanced_research_config import ResearchConfiguration
from src.llms import get_llm_by_type

logger = logging.getLogger(__name__)

class LiteratureEnhancedReportGenerator:
    """æ–‡çŒ®å¢å¼ºçš„æŠ¥å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self, model_name: str = "gemini", research_type: str = "default"):
        self.model_name = model_name
        
        # å¯¼å…¥é…ç½®
        from src.config.literature_config import get_literature_config
        self.config = get_literature_config(research_type)
        
        self.literature_cache = {}
        self.citation_count = 0
        self.citations = {}
        
    def generate_enhanced_comprehensive_report(
        self, 
        state: Dict[str, Any], 
        current_plan: Dict[str, Any],
        directions_list: List[str]
    ) -> str:
        """ç”Ÿæˆæ–‡çŒ®å¢å¼ºçš„ç»¼åˆæŠ¥å‘Š"""
        
        logger.info("ğŸ” å¼€å§‹ç”Ÿæˆæ–‡çŒ®å¢å¼ºçš„ç»¼åˆæŠ¥å‘Š")
        
        # ç¬¬ä¸€æ­¥ï¼šæ‰§è¡Œæ·±åº¦æ–‡çŒ®æœç´¢
        literature_database = self._execute_comprehensive_literature_search(
            state, current_plan, directions_list
        )
        
        # ç¬¬äºŒæ­¥ï¼šç”Ÿæˆæ–‡çŒ®é©±åŠ¨çš„ç»¼åˆæŠ¥å‘Š
        enhanced_report = self._generate_literature_driven_report(
            state, current_plan, directions_list, literature_database
        )
        
        logger.info(f"âœ… æ–‡çŒ®å¢å¼ºæŠ¥å‘Šç”Ÿæˆå®Œæˆï¼ŒåŒ…å« {self.citation_count} ç¯‡é«˜è´¨é‡æ–‡çŒ®å¼•ç”¨")
        
        return enhanced_report
    
    def _execute_comprehensive_literature_search(
        self, 
        state: Dict[str, Any], 
        current_plan: Dict[str, Any],
        directions_list: List[str]
    ) -> Dict[str, Any]:
        """æ‰§è¡Œå…¨é¢çš„æ–‡çŒ®æœç´¢"""
        
        logger.info("ğŸ“š å¼€å§‹æ‰§è¡Œå…¨é¢æ–‡çŒ®æœç´¢")
        
        # è·å–ä¸»è¦ç ”ç©¶æŸ¥è¯¢
        main_query = self._extract_main_research_query(state, current_plan)
        
        # æ„å»ºæœç´¢ç­–ç•¥
        search_strategies = self._build_search_strategies(main_query, directions_list)
        
        # æ‰§è¡Œæœç´¢
        all_literature = []
        
        for strategy_name, strategy in search_strategies.items():
            logger.info(f"ğŸ” æ‰§è¡Œæœç´¢ç­–ç•¥: {strategy_name}")
            
            try:
                results = self._execute_search_strategy(strategy)
                all_literature.extend(results)
                logger.info(f"âœ… {strategy_name} å®Œæˆï¼Œè·å¾— {len(results)} ç¯‡æ–‡çŒ®")
                time.sleep(0.5)  # é¿å…è¯·æ±‚è¿‡é¢‘
                
            except Exception as e:
                logger.warning(f"âš ï¸ æœç´¢ç­–ç•¥ {strategy_name} å¤±è´¥: {e}")
        
        # æ•´åˆå’Œæ’åº
        processed_literature = self._process_literature_results(all_literature)
        
        return processed_literature
    
    def _extract_main_research_query(self, state: Dict[str, Any], current_plan: Dict[str, Any]) -> str:
        """æå–ä¸»è¦ç ”ç©¶æŸ¥è¯¢"""
        
        # ä»è®¡åˆ’æ ‡é¢˜æå–
        title = current_plan.get("title", "")
        
        # ä»ç”¨æˆ·æ¶ˆæ¯æå–
        messages = state.get("messages", [])
        user_query = ""
        if messages:
            last_message = messages[-1]
            if isinstance(last_message, dict):
                user_query = last_message.get('content', '')
            else:
                user_query = getattr(last_message, 'content', '')
        
        # ç»„åˆæŸ¥è¯¢
        combined_query = f"{title} {user_query}".strip()
        
        # æ¸…ç†æŸ¥è¯¢
        cleaned_query = combined_query.replace("ç»¼åˆæŠ¥å‘Š", "").replace("ç ”ç©¶", "").strip()
        
        return cleaned_query[:150] if cleaned_query else "DXA imaging AI health prediction"
    
    def _build_search_strategies(self, main_query: str, directions_list: List[str]) -> Dict[str, Dict]:
        """æ„å»ºæœç´¢ç­–ç•¥"""
        
        strategies = {
            # æ ¸å¿ƒæ¦‚å¿µæœç´¢
            "core_systematic_reviews": {
                "queries": [
                    f"{main_query} systematic review",
                    f"{main_query} meta-analysis",
                    f"{main_query} comprehensive review"
                ],
                "sources": ["pubmed"],
                "max_results": 8
            },
            
            # æŠ€æœ¯æ–¹æ³•æœç´¢
            "technical_ai_methods": {
                "queries": [
                    f"{main_query} artificial intelligence",
                    f"{main_query} machine learning",
                    f"{main_query} deep learning"
                ],
                "sources": ["google_scholar", "pubmed"],
                "max_results": 6
            },
            
            # ä¸´åºŠåº”ç”¨æœç´¢
            "clinical_applications": {
                "queries": [
                    f"{main_query} clinical trial",
                    f"{main_query} clinical application",
                    f"{main_query} diagnostic accuracy"
                ],
                "sources": ["pubmed"],
                "max_results": 6
            },
            
            # ç”Ÿç‰©æœºåˆ¶æœç´¢
            "biological_mechanisms": {
                "queries": [
                    f"{main_query} mechanisms",
                    f"{main_query} pathophysiology",
                    f"{main_query} biomarkers"
                ],
                "sources": ["pubmed"],
                "max_results": 5
            }
        }
        
        return strategies
    
    def _execute_search_strategy(self, strategy: Dict) -> List[Dict]:
        """æ‰§è¡Œå•ä¸ªæœç´¢ç­–ç•¥"""
        
        all_results = []
        
        for query in strategy["queries"]:
            for source in strategy["sources"]:
                try:
                    if source == "pubmed":
                        tool = get_pubmed_search_tool(max_results=self.config.pubmed_max_results)
                        raw_results = tool.invoke({"query": query})
                        parsed_results = self._parse_pubmed_results(raw_results)
                        
                    elif source == "google_scholar":
                        tool = get_google_scholar_search_tool(top_k_results=self.config.scholar_max_results)
                        raw_results = tool.invoke({"query": query})
                        parsed_results = self._parse_scholar_results(raw_results)
                        
                    else:
                        continue
                    
                    all_results.extend(parsed_results)
                    
                except Exception as e:
                    logger.warning(f"æœç´¢å¤±è´¥ {source}: {query} - {e}")
                    continue
        
        return all_results
    
    def _parse_pubmed_results(self, raw_results: str) -> List[Dict]:
        """è§£æPubMedæœç´¢ç»“æœ"""
        
        literature = []
        
        if "Result" in raw_results:
            entries = raw_results.split("Result ")[1:]
            
            for entry in entries:
                lines = entry.split('\n')
                paper = {
                    'title': '',
                    'abstract': '',
                    'journal': '',
                    'authors': '',
                    'pmid': '',
                    'source': 'pubmed',
                    'quality_score': 0.85
                }
                
                for line in lines:
                    line = line.strip()
                    if line.startswith('Title: '):
                        paper['title'] = line.replace('Title: ', '').strip()
                    elif line.startswith('Abstract Snippet: '):
                        paper['abstract'] = line.replace('Abstract Snippet: ', '').strip()
                    elif line.startswith('Journal: '):
                        paper['journal'] = line.replace('Journal: ', '').strip()
                    elif line.startswith('Authors: '):
                        paper['authors'] = line.replace('Authors: ', '').strip()
                    elif line.startswith('PMID: '):
                        paper['pmid'] = line.replace('PMID: ', '').strip()
                
                if paper['title']:
                    paper['quality_score'] = self._assess_journal_quality(paper['journal'])
                    literature.append(paper)
        
        return literature
    
    def _parse_scholar_results(self, raw_results: str) -> List[Dict]:
        """è§£æGoogle Scholarç»“æœ"""
        
        literature = []
        
        if raw_results and raw_results.strip():
            lines = raw_results.split('\n')
            current_paper = None
            
            for line in lines:
                line = line.strip()
                if line.startswith('Title: '):
                    if current_paper and current_paper.get('title'):
                        literature.append(current_paper)
                    
                    current_paper = {
                        'title': line.replace('Title: ', ''),
                        'abstract': '',
                        'journal': '',
                        'source': 'google_scholar',
                        'quality_score': 0.75
                    }
                elif current_paper and line.startswith('Summary: '):
                    current_paper['abstract'] = line.replace('Summary: ', '')
                elif current_paper and line.startswith('Source: '):
                    source_info = line.replace('Source: ', '')
                    current_paper['journal'] = source_info
                    current_paper['quality_score'] = self._assess_journal_quality(source_info)
            
            if current_paper and current_paper.get('title'):
                literature.append(current_paper)
        
        return literature
    
    def _assess_journal_quality(self, journal_name: str) -> float:
        """è¯„ä¼°æœŸåˆŠè´¨é‡"""
        
        if not journal_name:
            return 0.5
        
        journal_lower = journal_name.lower()
        
        # é¡¶çº§æœŸåˆŠ
        top_journals = [
            'nature', 'science', 'cell', 'new england journal of medicine',
            'nejm', 'lancet', 'jama', 'nature medicine'
        ]
        
        # é«˜è´¨é‡æœŸåˆŠ
        high_quality = [
            'plos', 'bmj', 'circulation', 'radiology', 'ieee', 'acm'
        ]
        
        if any(tj in journal_lower for tj in top_journals):
            return 0.95
        elif any(hq in journal_lower for hq in high_quality):
            return 0.85
        else:
            return 0.75
    
    def _process_literature_results(self, all_literature: List[Dict]) -> Dict[str, Any]:
        """å¤„ç†æ–‡çŒ®æœç´¢ç»“æœ"""
        
        # å»é‡
        unique_literature = self._remove_duplicates(all_literature)
        
        # æ’åº
        sorted_literature = sorted(
            unique_literature, 
            key=lambda x: x.get('quality_score', 0.5), 
            reverse=True
        )
        
        # å–å‰Nç¯‡
        top_literature = sorted_literature[:self.config.max_literature_count]
        
        # åˆ†ç±»
        categorized = self._categorize_literature(top_literature)
        
        return {
            "total_count": len(top_literature),
            "literature": top_literature,
            "categorized": categorized
        }
    
    def _remove_duplicates(self, literature_list: List[Dict]) -> List[Dict]:
        """å»é‡å¤„ç†"""
        
        seen_titles = set()
        unique_papers = []
        
        for paper in literature_list:
            title = paper.get('title', '').lower().strip()
            if title and title not in seen_titles:
                unique_papers.append(paper)
                seen_titles.add(title)
        
        return unique_papers
    
    def _categorize_literature(self, literature_list: List[Dict]) -> Dict[str, List[Dict]]:
        """æ–‡çŒ®åˆ†ç±»"""
        
        categories = {
            "systematic_reviews": [],
            "clinical_trials": [],
            "technical_papers": [],
            "mechanism_studies": []
        }
        
        for paper in literature_list:
            title_abstract = f"{paper.get('title', '')} {paper.get('abstract', '')}".lower()
            
            if any(keyword in title_abstract for keyword in ['systematic review', 'meta-analysis']):
                categories["systematic_reviews"].append(paper)
            elif any(keyword in title_abstract for keyword in ['clinical trial', 'randomized']):
                categories["clinical_trials"].append(paper)
            elif any(keyword in title_abstract for keyword in ['artificial intelligence', 'machine learning']):
                categories["technical_papers"].append(paper)
            elif any(keyword in title_abstract for keyword in ['mechanism', 'pathway', 'molecular']):
                categories["mechanism_studies"].append(paper)
        
        return categories
    
    def _generate_literature_driven_report(
        self, 
        state: Dict[str, Any], 
        current_plan: Dict[str, Any],
        directions_list: List[str],
        literature_database: Dict[str, Any]
    ) -> str:
        """ç”Ÿæˆæ–‡çŒ®é©±åŠ¨çš„ç»¼åˆæŠ¥å‘Š"""
        
        logger.info("ğŸ“ å¼€å§‹ç”Ÿæˆæ–‡çŒ®é©±åŠ¨çš„ç»¼åˆæŠ¥å‘Š")
        
        # é‡ç½®å¼•ç”¨è®¡æ•°å™¨
        self.citation_count = 0
        self.citations = {}
        
        main_title = current_plan.get("title", "AIç ”ç©¶ç»¼åˆæŠ¥å‘Š")
        description = current_plan.get("description", "")
        
        # ç”ŸæˆæŠ¥å‘Šå„éƒ¨åˆ†
        sections = []
        
        # 1. æ ‡é¢˜å’Œæ‘˜è¦
        sections.append(self._generate_header(main_title, description, literature_database))
        
        # 2. æ–‡çŒ®ç»¼è¿°
        sections.append(self._generate_literature_review(literature_database))
        
        # 3. ç ”ç©¶èƒŒæ™¯
        sections.append(self._generate_background(literature_database))
        
        # 4. æŠ€æœ¯æ–¹æ³•
        sections.append(self._generate_methodology(literature_database))
        
        # 5. ç ”ç©¶æ–¹å‘
        sections.append(self._generate_directions_analysis(directions_list, literature_database))
        
        # 6. å…³é”®å‘ç°
        sections.append(self._generate_key_findings(literature_database))
        
        # 7. å‚è€ƒæ–‡çŒ®
        sections.append(self._generate_bibliography())
        
        # 8. ç»Ÿè®¡ä¿¡æ¯
        final_report = "\n\n".join(sections)
        sections.append(self._generate_statistics(final_report, literature_database))
        
        comprehensive_report = "\n\n".join(sections)
        
        logger.info(f"ğŸ“š æ–‡çŒ®é©±åŠ¨æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼Œæ€»é•¿åº¦: {len(comprehensive_report):,} å­—ç¬¦")
        
        return comprehensive_report
    
    def _generate_header(self, title: str, description: str, literature_db: Dict) -> str:
        """ç”ŸæˆæŠ¥å‘Šæ ‡é¢˜éƒ¨åˆ†"""
        
        return f"""# {title}

## ğŸ“‹ æŠ¥å‘Šä¿¡æ¯

- **ç”Ÿæˆæ—¥æœŸ**: {datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")}
- **æŠ¥å‘Šç±»å‹**: æ–‡çŒ®é©±åŠ¨çš„ç»¼åˆç ”ç©¶æŠ¥å‘Š
- **æ–‡çŒ®åŸºç¡€**: åŸºäº {literature_db.get('total_count', 0)} ç¯‡é«˜è´¨é‡å­¦æœ¯æ–‡çŒ®
- **AIæ¨¡å‹**: {self.model_name.upper()}

## ğŸ“– æ‰§è¡Œæ‘˜è¦

{description}

**æ–‡çŒ®æœç´¢æ¦‚å†µ**:
- ğŸ” **æœç´¢ç­–ç•¥**: å¤šå±‚æ¬¡å­¦æœ¯æ–‡çŒ®æœç´¢
- ğŸ“š **æ–‡çŒ®æ¥æº**: PubMedã€Google Scholarç­‰æƒå¨æ•°æ®åº“
- ğŸ† **è´¨é‡æ§åˆ¶**: ä»…åŒ…å«åŒè¡Œè¯„è®®çš„é«˜è´¨é‡å­¦æœ¯æ–‡çŒ®
- ğŸ“Š **å¼•ç”¨æ ‡å‡†**: éµå¾ªå­¦æœ¯å¼•ç”¨è§„èŒƒ

---"""
    
    def _generate_literature_review(self, literature_db: Dict) -> str:
        """ç”Ÿæˆæ–‡çŒ®ç»¼è¿°éƒ¨åˆ†"""
        
        categorized = literature_db.get("categorized", {})
        
        section = """## ğŸ“š æ–‡çŒ®ç»¼è¿°

### ğŸ”¬ ç ”ç©¶ç°çŠ¶æ¦‚è¿°

åŸºäºå¯¹ç›¸å…³é¢†åŸŸé«˜è´¨é‡æ–‡çŒ®çš„ç³»ç»Ÿæ€§åˆ†æï¼š"""
        
        # ç³»ç»Ÿæ€§ç»¼è¿°
        systematic_reviews = categorized.get("systematic_reviews", [])
        if systematic_reviews:
            section += f"""

#### ğŸ“‹ ç³»ç»Ÿæ€§ç»¼è¿°ä¸èŸèƒåˆ†æ ({len(systematic_reviews)} ç¯‡)

"""
            for i, paper in enumerate(systematic_reviews[:3], 1):
                citation = self._add_citation(paper)
                section += f"""
**{i}. {paper.get('title', 'Unknown Title')}** {citation}
- **æœŸåˆŠ**: {paper.get('journal', 'Unknown Journal')}
- **å…³é”®å‘ç°**: {paper.get('abstract', 'No abstract available')[:200]}...
"""
        
        # ä¸´åºŠè¯•éªŒ
        clinical_trials = categorized.get("clinical_trials", [])
        if clinical_trials:
            section += f"""

#### ğŸ¥ ä¸´åºŠè¯•éªŒç ”ç©¶ ({len(clinical_trials)} ç¯‡)

"""
            for i, paper in enumerate(clinical_trials[:3], 1):
                citation = self._add_citation(paper)
                section += f"""
**{i}. {paper.get('title', 'Unknown Title')}** {citation}
- **æœŸåˆŠ**: {paper.get('journal', 'Unknown Journal')}
- **ä¸´åºŠæ„ä¹‰**: {paper.get('abstract', 'No abstract available')[:200]}...
"""
        
        return section
    
    def _generate_background(self, literature_db: Dict) -> str:
        """ç”Ÿæˆç ”ç©¶èƒŒæ™¯"""
        
        section = """## ğŸ”¬ ç ”ç©¶èƒŒæ™¯ä¸ç†è®ºåŸºç¡€

### ğŸ§¬ ç”Ÿç‰©å­¦åŸºç¡€

"""
        
        mechanism_papers = literature_db.get("categorized", {}).get("mechanism_studies", [])
        if mechanism_papers:
            for paper in mechanism_papers[:2]:
                citation = self._add_citation(paper)
                section += f"""
**åˆ†å­æœºåˆ¶ç ”ç©¶** {citation} è¡¨æ˜ï¼Œ{paper.get('abstract', 'No abstract available')[:250]}...

"""
        
        section += """### ğŸ¤– æŠ€æœ¯å‘å±•ç°çŠ¶

"""
        
        tech_papers = literature_db.get("categorized", {}).get("technical_papers", [])
        if tech_papers:
            for paper in tech_papers[:2]:
                citation = self._add_citation(paper)
                section += f"""
**AIæŠ€æœ¯åº”ç”¨** {citation} çš„ç ”ç©¶æ˜¾ç¤ºï¼Œ{paper.get('abstract', 'No abstract available')[:250]}...

"""
        
        return section
    
    def _generate_methodology(self, literature_db: Dict) -> str:
        """ç”Ÿæˆæ–¹æ³•è®ºéƒ¨åˆ†"""
        
        section = """## ğŸ› ï¸ ç ”ç©¶æ–¹æ³•è®º

### ğŸ“Š æ•°æ®é‡‡é›†ä¸å¤„ç†

"""
        
        high_quality_papers = [
            paper for paper in literature_db.get("literature", [])
            if paper.get("quality_score", 0) > 0.85
        ][:5]
        
        for paper in high_quality_papers[:2]:
            citation = self._add_citation(paper)
            section += f"""
å‚è€ƒ {citation} çš„ç ”ç©¶æ–¹æ³•ï¼Œ{paper.get('abstract', 'No abstract available')[:200]}...

"""
        
        return section
    
    def _generate_directions_analysis(self, directions_list: List[str], literature_db: Dict) -> str:
        """ç”Ÿæˆç ”ç©¶æ–¹å‘åˆ†æ"""
        
        section = """## ğŸ¯ ç ”ç©¶æ–¹å‘ä¸æ–‡çŒ®æ”¯æ’‘

"""
        
        for i, direction in enumerate(directions_list[:8], 1):
            section += f"""### æ–¹å‘ {i}: {direction}

"""
            
            # ä¸ºæ¯ä¸ªæ–¹å‘åŒ¹é…ç›¸å…³æ–‡çŒ®
            relevant_papers = self._find_relevant_papers(direction, literature_db)
            
            if relevant_papers:
                section += """#### ğŸ“š ç›¸å…³æ–‡çŒ®æ”¯æ’‘

"""
                for paper in relevant_papers[:2]:
                    citation = self._add_citation(paper)
                    section += f"""
- **{paper.get('title', 'Unknown Title')}** {citation}
  - *æœŸåˆŠ*: {paper.get('journal', 'Unknown')}
  - *å…³é”®å†…å®¹*: {paper.get('abstract', 'No abstract')[:120]}...

"""
            
            section += """#### ğŸ”¬ ç ”ç©¶åˆ›æ–°ç‚¹

åŸºäºæ–‡çŒ®åˆ†æï¼Œè¯¥æ–¹å‘çš„ä¸»è¦åˆ›æ–°ç‚¹åŒ…æ‹¬æŠ€æœ¯æ–¹æ³•åˆ›æ–°ã€ç†è®ºæœºåˆ¶çªç ´å’Œä¸´åºŠåº”ç”¨ä»·å€¼ã€‚

---

"""
        
        return section
    
    def _find_relevant_papers(self, direction: str, literature_db: Dict) -> List[Dict]:
        """ä¸ºæ–¹å‘æ‰¾åˆ°ç›¸å…³æ–‡çŒ®"""
        
        direction_words = direction.lower().split()
        all_papers = literature_db.get("literature", [])
        
        relevant_papers = []
        
        for paper in all_papers:
            title = paper.get('title', '').lower()
            abstract = paper.get('abstract', '').lower()
            
            relevance_score = 0
            for word in direction_words:
                if len(word) > 3:
                    if word in title:
                        relevance_score += 2
                    elif word in abstract:
                        relevance_score += 1
            
            if relevance_score > 0:
                paper["relevance_score"] = relevance_score
                relevant_papers.append(paper)
        
        return sorted(relevant_papers, key=lambda x: x.get("relevance_score", 0), reverse=True)[:3]
    
    def _generate_key_findings(self, literature_db: Dict) -> str:
        """ç”Ÿæˆå…³é”®å‘ç°"""
        
        section = """## ğŸ’¡ å…³é”®å‘ç°ä¸æ´å¯Ÿ

åŸºäºé«˜è´¨é‡å­¦æœ¯æ–‡çŒ®çš„æ·±åº¦åˆ†æï¼š

### ğŸ” æŠ€æœ¯å‘å±•è¶‹åŠ¿

"""
        
        tech_papers = literature_db.get("categorized", {}).get("technical_papers", [])
        if tech_papers:
            for paper in tech_papers[:2]:
                citation = self._add_citation(paper)
                section += f"""
{citation} çš„ç ”ç©¶è¡¨æ˜ï¼š{paper.get('abstract', 'No abstract available')[:200]}...

"""
        
        section += """### ğŸ¥ ä¸´åºŠåº”ç”¨å‰æ™¯

"""
        
        clinical_papers = literature_db.get("categorized", {}).get("clinical_trials", [])
        if clinical_papers:
            for paper in clinical_papers[:2]:
                citation = self._add_citation(paper)
                section += f"""
{citation} çš„ä¸´åºŠç ”ç©¶æ˜¾ç¤ºï¼š{paper.get('abstract', 'No abstract available')[:200]}...

"""
        
        return section
    
    def _generate_bibliography(self) -> str:
        """ç”Ÿæˆå‚è€ƒæ–‡çŒ®"""
        
        section = """## ğŸ“– å‚è€ƒæ–‡çŒ®

"""
        
        if not self.citations:
            return section + "*æ³¨ï¼šå‚è€ƒæ–‡çŒ®åˆ—è¡¨ä¸ºç©º*"
        
        for citation_num, paper in self.citations.items():
            authors = paper.get('authors', 'Unknown Authors')
            title = paper.get('title', 'Unknown Title')
            journal = paper.get('journal', 'Unknown Journal')
            
            section += f"""
**[{citation_num}]** {authors}. *{title}*. {journal}.
"""
            
            if paper.get('pmid'):
                section += f" PMID: {paper['pmid']}"
            
            section += "\n"
        
        return section
    
    def _generate_statistics(self, report_content: str, literature_db: Dict) -> str:
        """ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯"""
        
        word_count = len(report_content)
        literature_count = literature_db.get("total_count", 0)
        
        return f"""---

## ğŸ“Š æŠ¥å‘Šç»Ÿè®¡ä¿¡æ¯

- **ğŸ“ æ€»å­—æ•°**: {word_count:,} å­—ç¬¦
- **ğŸ“š æ–‡çŒ®åŸºç¡€**: {literature_count} ç¯‡é«˜è´¨é‡å­¦æœ¯æ–‡çŒ®
- **ğŸ”— å¼•ç”¨æ•°é‡**: {self.citation_count} ä¸ªæ–‡çŒ®å¼•ç”¨
- **ğŸ“… ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

---
*æœ¬æŠ¥å‘Šç”±AIç§‘ç ”ç³»ç»ŸåŸºäºé«˜è´¨é‡å­¦æœ¯æ–‡çŒ®è‡ªåŠ¨ç”Ÿæˆ*"""
    
    def _add_citation(self, paper: Dict) -> str:
        """æ·»åŠ æ–‡çŒ®å¼•ç”¨"""
        
        # æ£€æŸ¥æ˜¯å¦å·²å¼•ç”¨
        for citation_num, cited_paper in self.citations.items():
            if cited_paper.get('title') == paper.get('title'):
                return f"[{citation_num}]"
        
        # æ·»åŠ æ–°å¼•ç”¨
        self.citation_count += 1
        citation_id = str(self.citation_count)
        self.citations[citation_id] = paper
        
        return f"[{citation_id}]"


def create_literature_enhanced_generator(
    model_name: str = "gemini",
    research_type: str = "default"
) -> LiteratureEnhancedReportGenerator:
    """åˆ›å»ºæ–‡çŒ®å¢å¼ºæŠ¥å‘Šç”Ÿæˆå™¨"""
    return LiteratureEnhancedReportGenerator(
        model_name=model_name,
        research_type=research_type
    ) 