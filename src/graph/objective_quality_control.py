# Copyright (c) 2025 Bytedance Ltd. and/or its affiliates
# SPDX-License-Identifier: MIT

"""
å®¢è§‚è´¨é‡æ§åˆ¶ç³»ç»Ÿ
================

æ›¿ä»£ä¸å¯é çš„LLMè‡ªè¯„ï¼Œä½¿ç”¨å®¢è§‚æŒ‡æ ‡è¿›è¡Œè´¨é‡æ§åˆ¶ï¼š
1. ğŸ” åŸºäºå†…å®¹é•¿åº¦å’Œç»“æ„çš„è´¨é‡è¯„ä¼°
2. ğŸ“Š åŸºäºå…³é”®è¯è¦†ç›–åº¦çš„å®Œæ•´æ€§è¯„ä¼°  
3. â±ï¸ åŸºäºè½®æ¬¡å’Œæ—¶é—´çš„åˆç†æ€§æ§åˆ¶
4. ğŸ¯ åŸºäºç”¨æˆ·åé¦ˆçš„å®é™…æ•ˆæœè¯„ä¼°

æ ¸å¿ƒåŸåˆ™ï¼š
- âŒ ä¸ä¾èµ–LLMè‡ªè¯„åˆ†æ•°
- âœ… ä½¿ç”¨å¯éªŒè¯çš„å®¢è§‚æŒ‡æ ‡
- âœ… ç®€å•ã€å¯é ã€å¯è°ƒè¯•
"""

import re
import logging
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from datetime import datetime

logger = logging.getLogger(__name__)


@dataclass
class ObjectiveQualityMetrics:
    """å®¢è§‚è´¨é‡æŒ‡æ ‡"""
    content_length: int = 0              # å†…å®¹é•¿åº¦
    key_sections_count: int = 0          # å…³é”®éƒ¨åˆ†æ•°é‡
    keyword_coverage_score: float = 0.0  # å…³é”®è¯è¦†ç›–åº¦
    structure_completeness: float = 0.0  # ç»“æ„å®Œæ•´æ€§
    time_spent_seconds: float = 0.0      # å¤„ç†æ—¶é—´
    round_number: int = 0                # è½®æ¬¡ç¼–å·
    
    def get_overall_score(self) -> float:
        """è®¡ç®—ç»¼åˆè´¨é‡åˆ†æ•°"""
        # åŸºäºå®¢è§‚æŒ‡æ ‡çš„åŠ æƒè¯„åˆ†
        length_score = min(self.content_length / 500, 1.0) * 0.3  # é•¿åº¦åˆ†æ•°
        section_score = min(self.key_sections_count / 3, 1.0) * 0.3  # ç»“æ„åˆ†æ•°
        keyword_score = self.keyword_coverage_score * 0.2  # å…³é”®è¯åˆ†æ•°
        structure_score = self.structure_completeness * 0.2  # å®Œæ•´æ€§åˆ†æ•°
        
        return length_score + section_score + keyword_score + structure_score


class ObjectiveQualityController:
    """å®¢è§‚è´¨é‡æ§åˆ¶å™¨"""
    
    def __init__(self):
        # ğŸ” ç ”ç©¶é¢†åŸŸå…³é”®è¯åº“
        self.research_keywords = {
            "ai": ["äººå·¥æ™ºèƒ½", "ai", "machine learning", "æ·±åº¦å­¦ä¹ ", "ç¥ç»ç½‘ç»œ", "ç®—æ³•"],
            "medical": ["åŒ»å­¦", "åŒ»ç–—", "å¥åº·", "è¯Šæ–­", "æ²»ç–—", "ä¸´åºŠ", "ç—…ç†"],
            "imaging": ["å½±åƒ", "å›¾åƒ", "dxa", "ct", "mri", "x-ray", "è¶…å£°"],
            "data": ["æ•°æ®", "dataset", "ç‰¹å¾", "æ ‡æ³¨", "è®­ç»ƒ", "æµ‹è¯•", "éªŒè¯"],
            "system": ["ç³»ç»Ÿ", "å¹³å°", "æ¡†æ¶", "æ¶æ„", "å¼€å‘", "éƒ¨ç½²", "åº”ç”¨"]
        }
        
        # ğŸ“‹ å¿…éœ€çš„è®¡åˆ’ç»“æ„ç»„ä»¶
        self.required_plan_sections = [
            "title", "thought", "steps", "locale"
        ]
        
        # ğŸ¯ ç ”ç©¶æ­¥éª¤ç±»å‹
        self.valid_step_types = [
            "research", "analysis", "processing", "writing"
        ]
    
    def evaluate_understanding_quality(
        self, 
        user_input: str, 
        ai_response: str,
        round_num: int,
        processing_time: float = 0.0
    ) -> ObjectiveQualityMetrics:
        """è¯„ä¼°ç†è§£è´¨é‡ - åŸºäºå®¢è§‚æŒ‡æ ‡"""
        
        logger.info(f"ğŸ” å®¢è§‚è´¨é‡è¯„ä¼° - ç†è§£é˜¶æ®µç¬¬{round_num}è½®")
        
        # 1. å†…å®¹é•¿åº¦è¯„ä¼°
        content_length = len(ai_response)
        
        # 2. å…³é”®è¯è¦†ç›–åº¦è¯„ä¼°
        keyword_coverage = self._calculate_keyword_coverage(user_input, ai_response)
        
        # 3. ç»“æ„å®Œæ•´æ€§è¯„ä¼°ï¼ˆç†è§£é˜¶æ®µï¼‰
        structure_score = self._evaluate_understanding_structure(ai_response)
        
        # 4. å…³é”®éƒ¨åˆ†è®¡æ•°
        key_sections = self._count_understanding_sections(ai_response)
        
        metrics = ObjectiveQualityMetrics(
            content_length=content_length,
            key_sections_count=key_sections,
            keyword_coverage_score=keyword_coverage,
            structure_completeness=structure_score,
            time_spent_seconds=processing_time,
            round_number=round_num
        )
        
        overall_score = metrics.get_overall_score()
        logger.info(f"ğŸ“Š ç†è§£è´¨é‡è¯„ä¼°ç»“æœ: {overall_score:.2f}")
        logger.info(f"   - å†…å®¹é•¿åº¦: {content_length} å­—ç¬¦")
        logger.info(f"   - å…³é”®è¯è¦†ç›–: {keyword_coverage:.2f}")
        logger.info(f"   - ç»“æ„å®Œæ•´: {structure_score:.2f}")
        logger.info(f"   - å…³é”®éƒ¨åˆ†: {key_sections} ä¸ª")
        
        return metrics
    
    def evaluate_planning_quality(
        self,
        plan_data: Dict[str, Any],
        user_input: str,
        round_num: int,
        processing_time: float = 0.0
    ) -> ObjectiveQualityMetrics:
        """è¯„ä¼°è§„åˆ’è´¨é‡ - åŸºäºå®¢è§‚æŒ‡æ ‡"""
        
        logger.info(f"ğŸ“‹ å®¢è§‚è´¨é‡è¯„ä¼° - è§„åˆ’é˜¶æ®µç¬¬{round_num}è½®")
        
        # 1. è®¡åˆ’å†…å®¹é•¿åº¦
        plan_text = str(plan_data)
        content_length = len(plan_text)
        
        # 2. å…³é”®è¯è¦†ç›–åº¦
        keyword_coverage = self._calculate_keyword_coverage(user_input, plan_text)
        
        # 3. è®¡åˆ’ç»“æ„å®Œæ•´æ€§
        structure_score = self._evaluate_plan_structure(plan_data)
        
        # 4. å…³é”®ç»„ä»¶è®¡æ•°
        key_sections = self._count_plan_sections(plan_data)
        
        metrics = ObjectiveQualityMetrics(
            content_length=content_length,
            key_sections_count=key_sections,
            keyword_coverage_score=keyword_coverage,
            structure_completeness=structure_score,
            time_spent_seconds=processing_time,
            round_number=round_num
        )
        
        overall_score = metrics.get_overall_score()
        logger.info(f"ğŸ“Š è§„åˆ’è´¨é‡è¯„ä¼°ç»“æœ: {overall_score:.2f}")
        logger.info(f"   - è®¡åˆ’é•¿åº¦: {content_length} å­—ç¬¦")
        logger.info(f"   - å…³é”®è¯è¦†ç›–: {keyword_coverage:.2f}")
        logger.info(f"   - ç»“æ„å®Œæ•´: {structure_score:.2f}")
        logger.info(f"   - å…³é”®ç»„ä»¶: {key_sections} ä¸ª")
        
        return metrics
    
    def should_continue_processing(
        self,
        metrics: ObjectiveQualityMetrics,
        max_rounds: int,
        min_quality_threshold: float = 0.4  # ğŸ”§ åŸºäºå®¢è§‚æŒ‡æ ‡çš„é˜ˆå€¼
    ) -> Tuple[bool, str]:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥ç»§ç»­å¤„ç† - åŸºäºå®¢è§‚æŒ‡æ ‡
        
        Returns:
            (should_continue, reason)
        """
        
        # 1. è½®æ¬¡é™åˆ¶ï¼ˆç¡¬æ€§æ¡ä»¶ï¼‰
        if metrics.round_number >= max_rounds:
            return False, f"è¾¾åˆ°æœ€å¤§è½®æ¬¡é™åˆ¶ ({max_rounds})"
        
        # 2. è´¨é‡è¾¾æ ‡ï¼ˆåŸºäºå®¢è§‚æŒ‡æ ‡ï¼‰
        overall_score = metrics.get_overall_score()
        if overall_score >= min_quality_threshold:
            return False, f"è´¨é‡è¾¾æ ‡ ({overall_score:.2f} >= {min_quality_threshold})"
        
        # 3. å†…å®¹é•¿åº¦æ£€æŸ¥
        if metrics.content_length < 50:
            return True, "å†…å®¹è¿‡çŸ­ï¼Œéœ€è¦è¡¥å……"
        
        # 4. ç»“æ„å®Œæ•´æ€§æ£€æŸ¥
        if metrics.structure_completeness < 0.5:
            return True, "ç»“æ„ä¸å®Œæ•´ï¼Œéœ€è¦æ”¹è¿›"
        
        # 5. å…³é”®è¯è¦†ç›–åº¦æ£€æŸ¥
        if metrics.keyword_coverage_score < 0.3:
            return True, "å…³é”®è¯è¦†ç›–ä¸è¶³ï¼Œéœ€è¦å®Œå–„"
        
        # é»˜è®¤ï¼šè´¨é‡æœªè¾¾æ ‡ï¼Œç»§ç»­å¤„ç†
        return True, f"è´¨é‡æœªè¾¾æ ‡ ({overall_score:.2f} < {min_quality_threshold})"
    
    def _calculate_keyword_coverage(self, user_input: str, ai_response: str) -> float:
        """è®¡ç®—å…³é”®è¯è¦†ç›–åº¦"""
        user_lower = user_input.lower()
        response_lower = ai_response.lower()
        
        total_keywords = 0
        covered_keywords = 0
        
        for category, keywords in self.research_keywords.items():
            for keyword in keywords:
                total_keywords += 1
                # å¦‚æœç”¨æˆ·è¾“å…¥åŒ…å«è¯¥å…³é”®è¯
                if keyword.lower() in user_lower:
                    # æ£€æŸ¥AIå“åº”æ˜¯å¦ä¹ŸåŒ…å«
                    if keyword.lower() in response_lower:
                        covered_keywords += 1
        
        return covered_keywords / total_keywords if total_keywords > 0 else 0.0
    
    def _evaluate_understanding_structure(self, ai_response: str) -> float:
        """è¯„ä¼°ç†è§£é˜¶æ®µçš„ç»“æ„å®Œæ•´æ€§"""
        score = 0.0
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å…³é”®ç†è§£è¦ç´ 
        understanding_indicators = [
            r"ç†è§£|understand|comprehend",
            r"éœ€æ±‚|requirement|need",
            r"ç›®æ ‡|goal|objective",
            r"æ–¹æ³•|method|approach",
            r"æ­¥éª¤|step|process"
        ]
        
        for indicator in understanding_indicators:
            if re.search(indicator, ai_response, re.IGNORECASE):
                score += 0.2
        
        return min(score, 1.0)
    
    def _evaluate_plan_structure(self, plan_data: Dict[str, Any]) -> float:
        """è¯„ä¼°è®¡åˆ’ç»“æ„å®Œæ•´æ€§"""
        if not isinstance(plan_data, dict):
            return 0.0
        
        score = 0.0
        
        # æ£€æŸ¥å¿…éœ€çš„è®¡åˆ’ç»„ä»¶
        for section in self.required_plan_sections:
            if section in plan_data and plan_data[section]:
                score += 0.25
        
        # æ£€æŸ¥æ­¥éª¤çš„è´¨é‡
        steps = plan_data.get("steps", [])
        if isinstance(steps, list) and len(steps) > 0:
            valid_steps = 0
            for step in steps:
                if isinstance(step, dict):
                    # æ£€æŸ¥æ­¥éª¤æ˜¯å¦åŒ…å«å¿…è¦å­—æ®µ
                    if all(field in step for field in ["step_type", "title", "description"]):
                        # æ£€æŸ¥æ­¥éª¤ç±»å‹æ˜¯å¦æœ‰æ•ˆ
                        if step.get("step_type") in self.valid_step_types:
                            valid_steps += 1
            
            if valid_steps > 0:
                score += min(valid_steps / len(steps), 0.25)
        
        return min(score, 1.0)
    
    def _count_understanding_sections(self, ai_response: str) -> int:
        """è®¡ç®—ç†è§£é˜¶æ®µçš„å…³é”®éƒ¨åˆ†æ•°é‡"""
        sections = 0
        
        # ä½¿ç”¨æ›´å®½æ¾çš„æ¨¡å¼åŒ¹é…
        section_patterns = [
            r"ç†è§£|understand",
            r"åˆ†æ|analysis", 
            r"å»ºè®®|suggestion",
            r"é—®é¢˜|question",
            r"æ–¹æ¡ˆ|solution"
        ]
        
        for pattern in section_patterns:
            if re.search(pattern, ai_response, re.IGNORECASE):
                sections += 1
        
        return sections
    
    def _count_plan_sections(self, plan_data: Dict[str, Any]) -> int:
        """è®¡ç®—è®¡åˆ’çš„å…³é”®ç»„ä»¶æ•°é‡"""
        if not isinstance(plan_data, dict):
            return 0
        
        sections = 0
        
        # æ£€æŸ¥åŸºæœ¬ç»„ä»¶
        basic_components = ["title", "thought", "steps"]
        for component in basic_components:
            if component in plan_data and plan_data[component]:
                sections += 1
        
        # æ£€æŸ¥æ­¥éª¤æ•°é‡
        steps = plan_data.get("steps", [])
        if isinstance(steps, list):
            sections += min(len(steps), 3)  # æœ€å¤šåŠ 3åˆ†
        
        return sections


class SimplifiedQualityController:
    """ç®€åŒ–çš„è´¨é‡æ§åˆ¶å™¨ - æç®€ç‰ˆæœ¬"""
    
    def __init__(self, max_rounds: int = 3):
        self.max_rounds = max_rounds
        self.objective_controller = ObjectiveQualityController()
    
    def should_continue_understanding(
        self, 
        user_input: str, 
        ai_response: str, 
        current_round: int
    ) -> Tuple[bool, str]:
        """ç®€åŒ–çš„ç†è§£é˜¶æ®µç»§ç»­åˆ¤æ–­"""
        
        # ğŸ”§ æç®€ç­–ç•¥ï¼šå›ºå®šè½®æ¬¡ï¼ŒåŸºäºåŸºæœ¬è´¨é‡æŒ‡æ ‡
        if current_round >= self.max_rounds:
            return False, f"è¾¾åˆ°æœ€å¤§è½®æ¬¡ ({self.max_rounds})"
        
        # åŸºæœ¬è´¨é‡æ£€æŸ¥
        if len(ai_response) < 100:
            return True, "å“åº”è¿‡çŸ­"
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«åŸºæœ¬ç†è§£è¦ç´ 
        has_understanding = any(keyword in ai_response.lower() for keyword in [
            "ç†è§£", "understand", "éœ€æ±‚", "ç›®æ ‡", "æ–¹æ³•"
        ])
        
        if not has_understanding:
            return True, "ç¼ºå°‘åŸºæœ¬ç†è§£è¦ç´ "
        
        return False, "åŸºæœ¬è´¨é‡è¾¾æ ‡"
    
    def should_continue_planning(
        self,
        plan_data: Dict[str, Any],
        user_input: str,
        current_round: int
    ) -> Tuple[bool, str]:
        """ç®€åŒ–çš„è§„åˆ’é˜¶æ®µç»§ç»­åˆ¤æ–­"""
        
        # ğŸ”§ æç®€ç­–ç•¥ï¼šå›ºå®šè½®æ¬¡ï¼ŒåŸºäºåŸºæœ¬ç»“æ„æ£€æŸ¥
        if current_round >= self.max_rounds:
            return False, f"è¾¾åˆ°æœ€å¤§è½®æ¬¡ ({self.max_rounds})"
        
        # åŸºæœ¬ç»“æ„æ£€æŸ¥
        if not isinstance(plan_data, dict):
            return True, "è®¡åˆ’æ ¼å¼é”™è¯¯"
        
        required_fields = ["title", "steps"]
        for field in required_fields:
            if field not in plan_data or not plan_data[field]:
                return True, f"ç¼ºå°‘å¿…è¦å­—æ®µ: {field}"
        
        # æ£€æŸ¥æ­¥éª¤æ•°é‡å’Œè´¨é‡
        steps = plan_data.get("steps", [])
        if not isinstance(steps, list) or len(steps) < 2:
            return True, "æ­¥éª¤æ•°é‡ä¸è¶³"
        
        return False, "åŸºæœ¬ç»“æ„å®Œæ•´"


# ğŸš€ ä¾¿æ·çš„å·¥å‚å‡½æ•°
def create_objective_quality_controller(mode: str = "simplified") -> Any:
    """
    åˆ›å»ºè´¨é‡æ§åˆ¶å™¨
    
    Args:
        mode: "simplified" (ç®€åŒ–ç‰ˆ) æˆ– "full" (å®Œæ•´ç‰ˆ)
    """
    if mode == "simplified":
        return SimplifiedQualityController(max_rounds=3)
    else:
        return ObjectiveQualityController()


def patch_enhanced_nodes_with_objective_quality():
    """
    ä½¿ç”¨å®¢è§‚è´¨é‡æ§åˆ¶å™¨ä¿®è¡¥å¢å¼ºèŠ‚ç‚¹
    
    è¿™ä¸ªå‡½æ•°ä¼šæ›¿æ¢åŸæœ‰çš„åŸºäºLLMè‡ªè¯„çš„è´¨é‡æ§åˆ¶é€»è¾‘
    """
    from src.graph import enhanced_planning_nodes
    
    # åˆ›å»ºå®¢è§‚è´¨é‡æ§åˆ¶å™¨
    quality_controller = SimplifiedQualityController(max_rounds=3)
    
    # ä¿®è¡¥ç†è§£èŠ‚ç‚¹çš„ç»§ç»­åˆ¤æ–­é€»è¾‘
    original_should_continue_understanding = enhanced_planning_nodes.EnhancedCoordinatorNode._should_continue_understanding
    
    def patched_should_continue_understanding(self, result, round_num):
        """ä½¿ç”¨å®¢è§‚æŒ‡æ ‡çš„ç»§ç»­åˆ¤æ–­"""
        # æå–å¿…è¦ä¿¡æ¯
        user_input = getattr(self, '_current_user_input', '')
        ai_response = result.thinking_process or ''
        
        should_continue, reason = quality_controller.should_continue_understanding(
            user_input, ai_response, round_num
        )
        
        logger.info(f"ğŸ” å®¢è§‚è´¨é‡åˆ¤æ–­: {reason}")
        return should_continue
    
    # åº”ç”¨ä¿®è¡¥
    enhanced_planning_nodes.EnhancedCoordinatorNode._should_continue_understanding = patched_should_continue_understanding
    
    logger.info("âœ… å·²åº”ç”¨å®¢è§‚è´¨é‡æ§åˆ¶ä¿®è¡¥")


if __name__ == "__main__":
    # æµ‹è¯•å®¢è§‚è´¨é‡æ§åˆ¶
    controller = ObjectiveQualityController()
    
    # æµ‹è¯•ç†è§£è´¨é‡è¯„ä¼°
    user_input = "å¼€å‘ä¸€ä¸ªåŸºäºAIçš„DXAå½±åƒåˆ†æç³»ç»Ÿ"
    ai_response = "æˆ‘ç†è§£æ‚¨éœ€è¦å¼€å‘ä¸€ä¸ªäººå·¥æ™ºèƒ½é©±åŠ¨çš„DXAå½±åƒåˆ†æç³»ç»Ÿï¼Œç”¨äºéª¨å¯†åº¦æ£€æµ‹å’Œå¥åº·é¢„æµ‹ã€‚"
    
    metrics = controller.evaluate_understanding_quality(user_input, ai_response, 1)
    print(f"ç†è§£è´¨é‡è¯„åˆ†: {metrics.get_overall_score():.2f}")
    
    # æµ‹è¯•è§„åˆ’è´¨é‡è¯„ä¼°
    plan_data = {
        "title": "AI-DXAå½±åƒåˆ†æç³»ç»Ÿå¼€å‘è®¡åˆ’",
        "thought": "è¯¦ç»†çš„å¼€å‘æ€è·¯",
        "steps": [
            {"step_type": "research", "title": "æŠ€æœ¯è°ƒç ”", "description": "è°ƒç ”ç›¸å…³æŠ€æœ¯"},
            {"step_type": "analysis", "title": "éœ€æ±‚åˆ†æ", "description": "åˆ†æå…·ä½“éœ€æ±‚"}
        ]
    }
    
    plan_metrics = controller.evaluate_planning_quality(plan_data, user_input, 1)
    print(f"è§„åˆ’è´¨é‡è¯„åˆ†: {plan_metrics.get_overall_score():.2f}")
    
    print("âœ… å®¢è§‚è´¨é‡æ§åˆ¶æµ‹è¯•å®Œæˆ") 