# Copyright (c) 2025 Bytedance Ltd. and/or its affiliates
# SPDX-License-Identifier: MIT

"""
å¢å¼ºèŠ‚ç‚¹æ‰§è¡Œå™¨ - æä¾›æ›´å¥½çš„é”™è¯¯å¤„ç†ã€å¹¶è¡Œæ‰§è¡Œå’ŒçŠ¶æ€ç®¡ç†
"""

import asyncio
import logging
import time
from typing import Dict, Any, List, Optional, Callable
from dataclasses import dataclass
from concurrent.futures import ThreadPoolExecutor, TimeoutError
from functools import wraps

from langchain_core.runnables import RunnableConfig
from langgraph.types import Command

logger = logging.getLogger(__name__)

@dataclass
class NodeExecutionResult:
    """èŠ‚ç‚¹æ‰§è¡Œç»“æœ"""
    success: bool
    data: Dict[str, Any]
    error: Optional[str] = None
    execution_time: float = 0.0
    retry_count: int = 0

@dataclass 
class NodeConfig:
    """èŠ‚ç‚¹é…ç½®"""
    timeout: int = 60
    max_retries: int = 3
    retry_delay: float = 1.0
    enable_parallel: bool = False
    critical: bool = True  # æ˜¯å¦ä¸ºå…³é”®èŠ‚ç‚¹

class EnhancedNodeExecutor:
    """å¢å¼ºèŠ‚ç‚¹æ‰§è¡Œå™¨"""
    
    def __init__(self):
        self.execution_history = []
        self.node_configs = {
            'background_investigation': NodeConfig(timeout=30, max_retries=2, critical=False),
            'planner': NodeConfig(timeout=45, max_retries=3, critical=True),
            'researcher': NodeConfig(timeout=120, max_retries=2, critical=True),
            'reporter': NodeConfig(timeout=90, max_retries=2, critical=True),
            'coder': NodeConfig(timeout=60, max_retries=2, critical=False)
        }
    
    def with_enhanced_execution(self, node_name: str):
        """è£…é¥°å™¨ï¼šä¸ºèŠ‚ç‚¹æ·»åŠ å¢å¼ºæ‰§è¡Œèƒ½åŠ›"""
        
        def decorator(func: Callable):
            @wraps(func)
            async def wrapper(*args, **kwargs):
                return await self.execute_node(node_name, func, *args, **kwargs)
            return wrapper
        return decorator
    
    async def execute_node(self, node_name: str, func: Callable, *args, **kwargs) -> Any:
        """å¢å¼ºèŠ‚ç‚¹æ‰§è¡Œ"""
        
        config = self.node_configs.get(node_name, NodeConfig())
        start_time = time.time()
        
        logger.info(f"ğŸš€ å¼€å§‹æ‰§è¡ŒèŠ‚ç‚¹: {node_name}")
        
        for attempt in range(config.max_retries + 1):
            try:
                # è®¾ç½®è¶…æ—¶æ‰§è¡Œ
                if asyncio.iscoroutinefunction(func):
                    result = await asyncio.wait_for(
                        func(*args, **kwargs),
                        timeout=config.timeout
                    )
                else:
                    # åŒæ­¥å‡½æ•°å¼‚æ­¥æ‰§è¡Œ
                    loop = asyncio.get_event_loop()
                    result = await asyncio.wait_for(
                        loop.run_in_executor(None, func, *args, **kwargs),
                        timeout=config.timeout
                    )
                
                execution_time = time.time() - start_time
                
                # è®°å½•æˆåŠŸæ‰§è¡Œ
                execution_result = NodeExecutionResult(
                    success=True,
                    data={'result': result},
                    execution_time=execution_time,
                    retry_count=attempt
                )
                self.execution_history.append((node_name, execution_result))
                
                logger.info(f"âœ… èŠ‚ç‚¹ {node_name} æ‰§è¡ŒæˆåŠŸï¼Œè€—æ—¶ {execution_time:.2f}sï¼Œé‡è¯• {attempt} æ¬¡")
                return result
                
            except TimeoutError:
                logger.warning(f"â° èŠ‚ç‚¹ {node_name} æ‰§è¡Œè¶…æ—¶ (å°è¯• {attempt + 1}/{config.max_retries + 1})")
                
            except Exception as e:
                logger.error(f"âŒ èŠ‚ç‚¹ {node_name} æ‰§è¡Œå¤±è´¥ (å°è¯• {attempt + 1}/{config.max_retries + 1}): {e}")
                
                if attempt < config.max_retries:
                    await asyncio.sleep(config.retry_delay * (attempt + 1))  # æŒ‡æ•°é€€é¿
                    continue
            
            # å¦‚æœæ˜¯éå…³é”®èŠ‚ç‚¹ï¼Œè¿”å›é™çº§ç»“æœ
            if not config.critical:
                logger.info(f"ğŸ”„ éå…³é”®èŠ‚ç‚¹ {node_name} æ‰§è¡Œå¤±è´¥ï¼Œè¿”å›é™çº§ç»“æœ")
                return self.get_fallback_result(node_name)
        
        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†
        execution_time = time.time() - start_time
        execution_result = NodeExecutionResult(
            success=False,
            data={},
            error=f"èŠ‚ç‚¹æ‰§è¡Œå¤±è´¥ï¼Œå·²é‡è¯• {config.max_retries} æ¬¡",
            execution_time=execution_time,
            retry_count=config.max_retries
        )
        self.execution_history.append((node_name, execution_result))
        
        if config.critical:
            logger.error(f"ğŸ’¥ å…³é”®èŠ‚ç‚¹ {node_name} æ‰§è¡Œå¤±è´¥ï¼Œç³»ç»Ÿå°†åœæ­¢")
            raise Exception(f"å…³é”®èŠ‚ç‚¹ {node_name} æ‰§è¡Œå¤±è´¥")
        else:
            logger.warning(f"âš ï¸ éå…³é”®èŠ‚ç‚¹ {node_name} æ‰§è¡Œå¤±è´¥ï¼Œç»§ç»­æ‰§è¡Œ")
            return self.get_fallback_result(node_name)
    
    def get_fallback_result(self, node_name: str) -> Any:
        """è·å–èŠ‚ç‚¹çš„é™çº§ç»“æœ"""
        
        fallback_results = {
            'background_investigation': Command(
                update={"background_investigation_results": "[]"},
                goto="planner"
            ),
            'coder': {
                'code_output': '# ä»£ç æ‰§è¡Œå¤±è´¥ï¼Œè¯·æ‰‹åŠ¨æ£€æŸ¥',
                'success': False
            }
        }
        
        return fallback_results.get(node_name, {})
    
    async def parallel_execute(self, tasks: List[Dict[str, Any]]) -> Dict[str, Any]:
        """å¹¶è¡Œæ‰§è¡Œå¤šä¸ªä»»åŠ¡"""
        
        logger.info(f"ğŸ”„ å¼€å§‹å¹¶è¡Œæ‰§è¡Œ {len(tasks)} ä¸ªä»»åŠ¡")
        
        async def execute_task(task):
            task_name = task['name']
            task_func = task['func']
            task_args = task.get('args', [])
            task_kwargs = task.get('kwargs', {})
            
            try:
                result = await self.execute_node(task_name, task_func, *task_args, **task_kwargs)
                return {'name': task_name, 'success': True, 'result': result}
            except Exception as e:
                logger.error(f"âŒ å¹¶è¡Œä»»åŠ¡ {task_name} æ‰§è¡Œå¤±è´¥: {e}")
                return {'name': task_name, 'success': False, 'error': str(e)}
        
        # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
        results = await asyncio.gather(*[execute_task(task) for task in tasks], return_exceptions=True)
        
        # æ•´ç†ç»“æœ
        success_count = sum(1 for r in results if isinstance(r, dict) and r.get('success'))
        logger.info(f"âœ… å¹¶è¡Œæ‰§è¡Œå®Œæˆï¼ŒæˆåŠŸ {success_count}/{len(tasks)} ä¸ªä»»åŠ¡")
        
        return {
            'total_tasks': len(tasks),
            'successful_tasks': success_count,
            'results': results
        }
    
    def get_execution_stats(self) -> Dict[str, Any]:
        """è·å–æ‰§è¡Œç»Ÿè®¡ä¿¡æ¯"""
        
        if not self.execution_history:
            return {}
        
        stats = {}
        for node_name, result in self.execution_history:
            if node_name not in stats:
                stats[node_name] = {
                    'total_executions': 0,
                    'successful_executions': 0,
                    'total_time': 0.0,
                    'total_retries': 0,
                    'avg_execution_time': 0.0,
                    'success_rate': 0.0
                }
            
            node_stats = stats[node_name]
            node_stats['total_executions'] += 1
            node_stats['total_time'] += result.execution_time
            node_stats['total_retries'] += result.retry_count
            
            if result.success:
                node_stats['successful_executions'] += 1
        
        # è®¡ç®—å¹³å‡å€¼å’ŒæˆåŠŸç‡
        for node_name, node_stats in stats.items():
            if node_stats['total_executions'] > 0:
                node_stats['avg_execution_time'] = node_stats['total_time'] / node_stats['total_executions']
                node_stats['success_rate'] = node_stats['successful_executions'] / node_stats['total_executions']
        
        return stats
    
    def log_performance_summary(self):
        """è¾“å‡ºæ€§èƒ½æ€»ç»“"""
        
        stats = self.get_execution_stats()
        
        logger.info("ğŸ“Š èŠ‚ç‚¹æ‰§è¡Œæ€§èƒ½æ€»ç»“:")
        for node_name, node_stats in stats.items():
            logger.info(
                f"  {node_name}: "
                f"æˆåŠŸç‡ {node_stats['success_rate']:.2%}, "
                f"å¹³å‡è€—æ—¶ {node_stats['avg_execution_time']:.2f}s, "
                f"æ€»é‡è¯• {node_stats['total_retries']} æ¬¡"
            )

# åˆ›å»ºå…¨å±€å®ä¾‹
enhanced_node_executor = EnhancedNodeExecutor()

# ä¾¿æ·è£…é¥°å™¨
def enhanced_execution(node_name: str):
    """ä¾¿æ·çš„å¢å¼ºæ‰§è¡Œè£…é¥°å™¨"""
    return enhanced_node_executor.with_enhanced_execution(node_name) 