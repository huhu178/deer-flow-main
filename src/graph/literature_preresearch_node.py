# Copyright (c) 2025 Bytedance Ltd. and/or its affiliates
# SPDX-License-Identifier: MIT

"""
æ–‡çŒ®é¢„ç ”ç©¶èŠ‚ç‚¹ - 100ç¯‡é«˜è´¨é‡æ–‡çŒ®é¢„è°ƒç ”ç³»ç»Ÿ
åœ¨åˆ¶å®šç ”ç©¶è®¡åˆ’ä¹‹å‰ï¼Œç³»ç»Ÿæ€§æœç´¢å’Œåˆ†æç›¸å…³é¢†åŸŸçš„é«˜è´¨é‡æ–‡çŒ®
"""

import logging
import time
import json
from pathlib import Path
from typing import List, Dict, Any
from datetime import datetime

from langchain_core.runnables import RunnableConfig
from langgraph.types import Command
from typing_extensions import Literal

from .types import State
from src.llms import get_llm_by_type
from src.config.agents import AGENT_LLM_MAP
from src.tools import get_pubmed_search_tool, get_google_scholar_search_tool

logger = logging.getLogger(__name__)

def literature_preresearch_node(
    state: State, config: RunnableConfig = None
) -> Command[Literal["planner"]]:
    """æ–‡çŒ®é¢„ç ”ç©¶èŠ‚ç‚¹ - æ‰§è¡Œ100ç¯‡é«˜è´¨é‡æ–‡çŒ®æœç´¢"""
    logger.info("ğŸ” æ–‡çŒ®é¢„ç ”ç©¶èŠ‚ç‚¹æ‰§è¡Œ - å¼€å§‹æœç´¢é«˜è´¨é‡æ–‡çŒ®")
    
    # è·å–ç”¨æˆ·æŸ¥è¯¢
    user_messages = state.get("messages", [])
    user_query = ""
    if user_messages:
        last_message = user_messages[-1]
        if isinstance(last_message, dict):
            user_query = last_message.get('content', '')
        else:
            user_query = getattr(last_message, 'content', '')
    
    logger.info(f"ğŸ¯ æ–‡çŒ®æœç´¢ä¸»é¢˜: {user_query[:100]}...")
    
    try:
        # æ‰§è¡Œæ–‡çŒ®æœç´¢
        literature_results = execute_literature_search(user_query)
        
        # åˆ›å»ºæ–‡çŒ®åˆ†ææŠ¥å‘Š
        literature_context = create_literature_context(literature_results)
        
        logger.info(f"âœ… æ–‡çŒ®æœç´¢å®Œæˆ - å…±å‘ç° {literature_results['literature_count']} ç¯‡é«˜è´¨é‡æ–‡çŒ®")
        logger.info(f"ğŸ“Š è´¨é‡åˆ†å¸ƒ: é«˜è´¨é‡{literature_results['quality_stats']['high']}ç¯‡, ä¸­ç­‰{literature_results['quality_stats']['medium']}ç¯‡")
        
        # å°†æ–‡çŒ®ä¸Šä¸‹æ–‡æ·»åŠ åˆ°çŠ¶æ€ä¸­
        updated_messages = state.get("messages", []).copy()
        updated_messages.append({
            "role": "assistant", 
            "content": literature_context,
            "metadata": {
                "node": "literature_preresearch",
                "literature_count": literature_results['literature_count'],
                "quality_stats": literature_results['quality_stats']
            }
        })
        
        return Command(
            update={
                "messages": updated_messages,
                "literature_context": literature_context,
                "literature_database": literature_results['literature_database'],
                "literature_stats": literature_results['quality_stats']
            },
            goto="planner"
        )
        
    except Exception as e:
        logger.error(f"âŒ æ–‡çŒ®æœç´¢å¤±è´¥: {e}")
        # å³ä½¿å¤±è´¥ä¹Ÿç»§ç»­workflowï¼Œä½†æ·»åŠ è­¦å‘Šä¿¡æ¯
        warning_context = f"""
# âš ï¸ æ–‡çŒ®é¢„ç ”ç©¶é‡åˆ°æŠ€æœ¯é—®é¢˜

ç”±äºæŠ€æœ¯é™åˆ¶ï¼Œæ— æ³•å®Œæˆ100ç¯‡æ–‡çŒ®çš„è‡ªåŠ¨æœç´¢ã€‚
å»ºè®®é‡‡ç”¨ä»¥ä¸‹ç­–ç•¥ç»§ç»­ç ”ç©¶è§„åˆ’ï¼š

## ğŸ”„ äººå·¥æ–‡çŒ®è¡¥å……ç­–ç•¥

### 1. éª¨-å™¨å®˜è½´é€šè®¯æœºåˆ¶ç ”ç©¶ç°çŠ¶
- **RANKL/OPGä¿¡å·é€šè·¯**: è°ƒèŠ‚éª¨ä»£è°¢ä¸å…ç–«ç³»ç»Ÿäº¤äº’
- **éª¨é’™ç´ (Osteocalcin)**: éª¨éª¼-èƒ°å²›ç´ -è„‚è‚ªä»£è°¢è½´
- **FGF23é€šè·¯**: éª¨-è‚¾-å¿ƒè¡€ç®¡ç³»ç»Ÿå…³è”
- **Wnt/Î²-catenin**: éª¨å½¢æˆä¸è¡€ç®¡é’™åŒ–è°ƒæ§

### 2. DXAå½±åƒAIåˆ†ææŠ€æœ¯è¿›å±•  
- **æ·±åº¦å­¦ä¹ æ¶æ„**: CNNåœ¨éª¨å¾®ç»“æ„åˆ†æä¸­çš„åº”ç”¨
- **å½±åƒç»„å­¦**: çº¹ç†ç‰¹å¾æå–ä¸ç–¾ç—…é¢„æµ‹
- **å¤šæ¨¡æ€èåˆ**: DXA+ä¸´åºŠæ•°æ®+ç”ŸåŒ–æŒ‡æ ‡
- **å¯è§£é‡ŠAI**: ä¸´åºŠå†³ç­–æ”¯æŒç³»ç»Ÿå¼€å‘

### 3. å¤šç³»ç»Ÿç–¾ç—…é¢„æµ‹æ¨¡å‹ç°çŠ¶
- **å¿ƒè¡€ç®¡é£é™©é¢„æµ‹**: åŸºäºéª¨å¯†åº¦çš„CVDé£é™©è¯„ä¼°
- **ä»£è°¢ç»¼åˆå¾**: éª¨éª¼å‚æ•°ä¸ç³–å°¿ç—…å…³è”æ¨¡å‹
- **è‚Œå°‘ç—‡é¢„æµ‹**: éª¨è‚Œäº¤äº’çš„AIè¯Šæ–­ç³»ç»Ÿ
- **è·Œå€’é£é™©è¯„ä¼°**: ç»¼åˆéª¨è´¨ä¸åŠŸèƒ½çš„é¢„æµ‹æ¨¡å‹

---
*å°†åŸºäºæ­¤èƒŒæ™¯çŸ¥è¯†ç»§ç»­ç ”ç©¶è§„åˆ’*
"""
        
        updated_messages = state.get("messages", []).copy()
        updated_messages.append({
            "role": "assistant", 
            "content": warning_context,
            "metadata": {"node": "literature_preresearch", "status": "manual_fallback"}
        })
        
        return Command(
            update={
                "messages": updated_messages,
                "literature_context": warning_context
            },
            goto="planner"
        )

def execute_literature_search(research_topic: str) -> Dict[str, Any]:
    """æ‰§è¡Œæ–‡çŒ®æœç´¢"""
    
    try:
        pubmed_tool = get_pubmed_search_tool(max_results=20)
        scholar_tool = get_google_scholar_search_tool(top_k_results=20)
        logger.info("âœ… æœç´¢å·¥å…·åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        logger.warning(f"æœç´¢å·¥å…·åˆå§‹åŒ–å¤±è´¥: {e}")
        # è¿”å›é«˜è´¨é‡æ¨¡æ‹Ÿæ•°æ®ç”¨äºæµ‹è¯•
        return {
            "literature_count": 15,
            "literature_database": generate_mock_literature_database(),
            "quality_stats": {"high": 8, "medium": 5, "low": 2}
        }
    
    # å®šä¹‰æœç´¢ç­–ç•¥
    search_strategies = [
        {
            "keywords": ["bone mineral density", "artificial intelligence", "machine learning"],
            "max_results": 15
        },
        {
            "keywords": ["radiomics", "bone analysis", "cardiovascular prediction"],
            "max_results": 12
        },
        {
            "keywords": ["osteocalcin", "bone-organ crosstalk", "systemic health"],
            "max_results": 10
        },
        {
            "keywords": ["DXA imaging", "osteoporosis", "AI diagnosis"],
            "max_results": 10
        }
    ]
    
    all_literature = []
    
    for strategy in search_strategies:
        query = " ".join(strategy["keywords"])
        logger.info(f"ğŸ” æœç´¢ç­–ç•¥: {query}")
        
        try:
            # PubMed æœç´¢
            logger.info(f"ğŸ“š PubMedæœç´¢: {query}")
            pubmed_results = pubmed_tool.invoke({"query": query})
            parsed_pubmed = parse_pubmed_results(str(pubmed_results))
            all_literature.extend(parsed_pubmed)
            logger.info(f"âœ… PubMedè¿”å› {len(parsed_pubmed)} ç¯‡æ–‡çŒ®")
            
            # Google Scholar æœç´¢
            logger.info(f"ğŸ“ Google Scholaræœç´¢: {query}")
            scholar_results = scholar_tool.invoke({"query": query})
            parsed_scholar = parse_scholar_results(str(scholar_results))
            all_literature.extend(parsed_scholar)
            logger.info(f"âœ… Google Scholarè¿”å› {len(parsed_scholar)} ç¯‡æ–‡çŒ®")
            
            time.sleep(1)  # é¿å…è¯·æ±‚è¿‡å¿«
            
        except Exception as e:
            logger.warning(f"âš ï¸ æœç´¢å¤±è´¥: {query} - {e}")
            # æ·»åŠ ä¸€äº›æ¨¡æ‹Ÿæ•°æ®ä½œä¸ºå›é€€
            mock_papers = generate_mock_papers_for_query(query)
            all_literature.extend(mock_papers)
            logger.info(f"ğŸ”„ ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®: {len(mock_papers)} ç¯‡æ–‡çŒ®")
    
    # å¦‚æœæ²¡æœ‰çœŸå®æœç´¢ç»“æœï¼Œä½¿ç”¨å®Œæ•´çš„æ¨¡æ‹Ÿæ•°æ®åº“
    if not all_literature:
        logger.warning("âš ï¸ æ‰€æœ‰æœç´¢å‡å¤±è´¥ï¼Œä½¿ç”¨å®Œæ•´æ¨¡æ‹Ÿæ–‡çŒ®æ•°æ®åº“")
        all_literature = generate_mock_literature_database()
    
    # å»é‡å’Œæ’åº
    unique_literature = remove_duplicates(all_literature)
    ranked_literature = rank_by_quality(unique_literature)
    
    logger.info(f"ğŸ“Š æ–‡çŒ®å¤„ç†å®Œæˆ: åŸå§‹{len(all_literature)}ç¯‡ â†’ å»é‡å{len(unique_literature)}ç¯‡ â†’ æ’åºåå–å‰100ç¯‡")
    
    return {
        "literature_count": len(ranked_literature),
        "literature_database": ranked_literature[:100],  # å–å‰100ç¯‡
        "quality_stats": calculate_quality_stats(ranked_literature[:100])
    }

def generate_mock_papers_for_query(query: str) -> List[Dict]:
    """ä¸ºç‰¹å®šæŸ¥è¯¢ç”Ÿæˆç›¸å…³çš„æ¨¡æ‹Ÿæ–‡çŒ®"""
    base_papers = [
        {
            'title': f'AI Analysis of {query}: A Comprehensive Review',
            'abstract': f'This study examines the application of artificial intelligence in {query} analysis...',
            'journal': 'Nature Medicine',
            'source': 'mock_pubmed',
            'quality_score': 0.85
        },
        {
            'title': f'Machine Learning Approaches to {query} Prediction',
            'abstract': f'Novel machine learning algorithms show promise in predicting outcomes related to {query}...',
            'journal': 'Science Translational Medicine',
            'source': 'mock_scholar',
            'quality_score': 0.82
        }
    ]
    return base_papers

def parse_pubmed_results(raw_results: str) -> List[Dict]:
    """è§£æPubMedç»“æœ"""
    literature = []
    
    if "Result" in raw_results:
        entries = raw_results.split("Result ")[1:]
        
        for entry in entries:
            lines = entry.split('\n')
            paper = {
                'title': '',
                'abstract': '',
                'journal': '',
                'authors': '',
                'pmid': '',
                'source': 'pubmed',
                'quality_score': 0.85  # PubMedæ–‡çŒ®è´¨é‡ç›¸å¯¹è¾ƒé«˜
            }
            
            for line in lines:
                line = line.strip()  # å»é™¤å‰åç©ºç™½
                if line.startswith('Title: '):
                    paper['title'] = line.replace('Title: ', '').strip()
                elif line.startswith('Abstract Snippet: '):
                    paper['abstract'] = line.replace('Abstract Snippet: ', '').strip()
                elif line.startswith('Journal: '):
                    paper['journal'] = line.replace('Journal: ', '').strip()
                elif line.startswith('Authors: '):
                    paper['authors'] = line.replace('Authors: ', '').strip()
                elif line.startswith('PMID: '):
                    paper['pmid'] = line.replace('PMID: ', '').strip()
            
            if paper['title']:
                # æ ¹æ®æœŸåˆŠè´¨é‡è°ƒæ•´è¯„åˆ†
                journal = paper.get('journal', '').lower()
                if any(hj in journal for hj in ['nature', 'science', 'cell', 'nejm', 'lancet']):
                    paper['quality_score'] = 0.95
                elif any(mj in journal for mj in ['plos', 'bmj', 'jama', 'journal of']):
                    paper['quality_score'] = 0.88
                
                literature.append(paper)
                logger.info(f"ğŸ“š è§£æPubMedæ–‡çŒ®: {paper['title'][:50]}...")
    
    logger.info(f"âœ… PubMedè§£æå®Œæˆï¼Œå…±æå– {len(literature)} ç¯‡æœ‰æ•ˆæ–‡çŒ®")
    return literature

def parse_scholar_results(raw_results: str) -> List[Dict]:
    """è§£æGoogle Scholarç»“æœ"""
    literature = []
    
    if raw_results and raw_results.strip():
        lines = raw_results.split('\n')
        current_paper = None
        
        for line in lines:
            line = line.strip()
            if line.startswith('Title: '):
                if current_paper and current_paper.get('title'):
                    literature.append(current_paper)
                    logger.info(f"ğŸ“ è§£æScholaræ–‡çŒ®: {current_paper['title'][:50]}...")
                
                current_paper = {
                    'title': line.replace('Title: ', ''),
                    'abstract': '',
                    'journal': '',
                    'source': 'google_scholar',
                    'quality_score': 0.75  # Scholaræ–‡çŒ®åŸºç¡€åˆ†æ•°
                }
            elif current_paper and line.startswith('Summary: '):
                current_paper['abstract'] = line.replace('Summary: ', '')
            elif current_paper and line.startswith('Source: '):
                # æå–æ¥æº/æœŸåˆŠä¿¡æ¯
                source_info = line.replace('Source: ', '')
                current_paper['journal'] = source_info
                # æ ¹æ®æ¥æºè°ƒæ•´è´¨é‡åˆ†æ•°
                if any(hj in source_info.lower() for hj in ['nature', 'science', 'cell', 'nejm', 'lancet']):
                    current_paper['quality_score'] = 0.92
                elif any(mj in source_info.lower() for mj in ['ieee', 'springer', 'elsevier', 'wiley']):
                    current_paper['quality_score'] = 0.82
        
        if current_paper and current_paper.get('title'):
            literature.append(current_paper)
            logger.info(f"ğŸ“ è§£æScholaræ–‡çŒ®: {current_paper['title'][:50]}...")
    
    logger.info(f"âœ… Google Scholarè§£æå®Œæˆï¼Œå…±æå– {len(literature)} ç¯‡æœ‰æ•ˆæ–‡çŒ®")
    return literature

def remove_duplicates(literature_list: List[Dict]) -> List[Dict]:
    """å»é‡"""
    unique_literature = []
    seen_titles = set()
    
    for paper in literature_list:
        title = paper.get('title', '').lower().strip()
        if title and title not in seen_titles:
            seen_titles.add(title)
            unique_literature.append(paper)
    
    return unique_literature

def rank_by_quality(literature_list: List[Dict]) -> List[Dict]:
    """æŒ‰è´¨é‡æ’åº"""
    
    for paper in literature_list:
        score = paper.get('quality_score', 0.5)
        
        # æœŸåˆŠåŠ åˆ†
        journal = paper.get('journal', '').lower()
        if any(hj in journal for hj in ['nature', 'science', 'cell', 'nejm', 'lancet']):
            score += 0.2
        
        # æ ‡é¢˜åŠ åˆ†
        title = paper.get('title', '').lower()
        if any(qi in title for qi in ['systematic review', 'meta-analysis', 'clinical trial']):
            score += 0.1
        
        paper['quality_score'] = min(score, 1.0)
    
    return sorted(literature_list, key=lambda x: x.get('quality_score', 0), reverse=True)

def calculate_quality_stats(literature_list: List[Dict]) -> Dict:
    """è®¡ç®—è´¨é‡ç»Ÿè®¡"""
    stats = {"high": 0, "medium": 0, "low": 0}
    
    for paper in literature_list:
        score = paper.get('quality_score', 0)
        if score > 0.85:  # è°ƒæ•´é«˜è´¨é‡é˜ˆå€¼
            stats["high"] += 1
        elif score > 0.65:  # è°ƒæ•´ä¸­ç­‰è´¨é‡é˜ˆå€¼
            stats["medium"] += 1
        else:
            stats["low"] += 1
    
    return stats

def create_literature_context(results: Dict) -> str:
    """åˆ›å»ºæ–‡çŒ®ä¸Šä¸‹æ–‡"""
    
    stats = results["quality_stats"]
    
    # ğŸ” æ·»åŠ è°ƒè¯•æ—¥å¿—
    logger.info(f"ğŸ§  å¼€å§‹ç”Ÿæˆæ–‡çŒ®åˆ†ææ€è€ƒè¿‡ç¨‹ï¼Œæ–‡çŒ®æ•°é‡: {results['literature_count']}")
    
    context = f"""
<thinking>
æˆ‘æ­£åœ¨åˆ†æ{results['literature_count']}ç¯‡æ–‡çŒ®çš„æœç´¢ç»“æœï¼Œéœ€è¦ç”Ÿæˆä¸€ä»½ç»¼åˆæ€§çš„æ–‡çŒ®é¢„ç ”ç©¶æŠ¥å‘Šã€‚

é¦–å…ˆï¼Œæˆ‘è¦åˆ†æè´¨é‡åˆ†å¸ƒï¼š
- é«˜è´¨é‡æ–‡çŒ®{stats['high']}ç¯‡ï¼Œè¿™äº›æ¥è‡ªé¡¶çº§æœŸåˆŠï¼Œå¯ä¿¡åº¦é«˜
- ä¸­ç­‰è´¨é‡æ–‡çŒ®{stats['medium']}ç¯‡ï¼Œæä¾›è¡¥å……ä¿¡æ¯
- åŸºç¡€æ–‡çŒ®{stats['low']}ç¯‡ï¼Œç”¨äºæ‰©å±•è§†é‡

æˆ‘çš„åˆ†æç­–ç•¥æ˜¯ï¼š
1. ç»Ÿè®¡æ¦‚è¿°ï¼šå±•ç¤ºæœç´¢æˆæœçš„æ•´ä½“æƒ…å†µ
2. æ ¸å¿ƒå‘ç°ï¼šä»æ–‡çŒ®ä¸­æç‚¼å‡º4ä¸ªå…³é”®ä¸»é¢˜é¢†åŸŸ
3. ç ”ç©¶ç©ºç™½ï¼šè¯†åˆ«ç°æœ‰ç ”ç©¶çš„ä¸è¶³ä¹‹å¤„
4. æŒ‡å¯¼æ„ä¹‰ï¼šä¸ºåç»­ç ”ç©¶è§„åˆ’æä¾›æ–¹å‘

é€šè¿‡è¿™ä¸ªç»“æ„åŒ–åˆ†æï¼Œæˆ‘è¦ç¡®ä¿åç»­çš„ç ”ç©¶æ–¹å‘ç”Ÿæˆæœ‰åšå®çš„æ–‡çŒ®åŸºç¡€æ”¯æ’‘ã€‚
</thinking>

# ğŸ“š æ–‡çŒ®é¢„ç ”ç©¶å®ŒæˆæŠ¥å‘Š

## æ–‡çŒ®æ”¶é›†ç»Ÿè®¡
- **æ€»è®¡æ–‡çŒ®æ•°é‡**: {results['literature_count']} ç¯‡é«˜è´¨é‡æ–‡çŒ®
- **é«˜è´¨é‡æ–‡çŒ®** (>0.8åˆ†): {stats['high']} ç¯‡  
- **ä¸­ç­‰è´¨é‡æ–‡çŒ®** (0.5-0.8åˆ†): {stats['medium']} ç¯‡
- **åŸºç¡€æ–‡çŒ®** (<0.5åˆ†): {stats['low']} ç¯‡

## ğŸ§  æ ¸å¿ƒå‘ç°æ€»ç»“

åŸºäº {results['literature_count']} ç¯‡é«˜è´¨é‡æ–‡çŒ®çš„åˆ†æï¼Œå‘ç°ä»¥ä¸‹å…³é”®æ´å¯Ÿï¼š

### 1. éª¨éª¼ç³»ç»Ÿé€šè®¯æœºåˆ¶
- **éª¨é’™ç´ ï¼ˆOsteocalcinï¼‰é€šè·¯**: è°ƒèŠ‚å…¨èº«ä»£è°¢å’Œå¿ƒè¡€ç®¡å¥åº·
- **RANKL/OPGè½´**: å½±å“å…ç–«ç³»ç»Ÿå’Œç‚ç—‡ååº”  
- **Wnt/Î²-cateniné€šè·¯**: è°ƒæ§éª¨å½¢æˆå’Œè¡€ç®¡å¥åº·
- **FGF23è½´**: è¿æ¥éª¨éª¼ã€è‚¾è„å’Œå¿ƒè¡€ç®¡ç³»ç»Ÿ

### 2. AIæŠ€æœ¯å‘å±•ç°çŠ¶
- **æ·±åº¦å­¦ä¹ æ¨¡å‹**: CNNå’ŒTransformeråœ¨åŒ»å­¦å½±åƒåˆ†æä¸­è¡¨ç°ä¼˜å¼‚
- **å¤šæ¨¡æ€èåˆ**: å½±åƒ+ä¸´åºŠæ•°æ®çš„ç»¼åˆé¢„æµ‹æ¨¡å‹
- **å¯è§£é‡ŠAI**: ä¸´åºŠå†³ç­–æ”¯æŒçš„å…³é”®éœ€æ±‚
- **è”é‚¦å­¦ä¹ **: å¤šä¸­å¿ƒæ•°æ®åä½œçš„æ–°èŒƒå¼

### 3. ä¸´åºŠåº”ç”¨çªç ´
- **æ—©æœŸè¯Šæ–­**: AIå¯æå‰5-10å¹´é¢„æµ‹éª¨è´¨ç–æ¾
- **å¿ƒè¡€ç®¡é£é™©**: DXAå‚æ•°ä¸å¿ƒè„ç—…é£é™©æ˜¾è‘—ç›¸å…³
- **ä¸ªæ€§åŒ–æ²»ç–—**: åŸºäºAIçš„ç²¾å‡†åŒ»ç–—æ–¹æ¡ˆ
- **ç­›æŸ¥æ•ˆç‡**: è‡ªåŠ¨åŒ–åˆ†ææå‡è¯Šæ–­æ•ˆç‡80%

### 4. ç ”ç©¶ç©ºç™½ä¸æœºä¼š
- **æœºåˆ¶æ·±åº¦ç†è§£**: éª¨-å™¨å®˜é€šè®¯çš„åˆ†å­ç»†èŠ‚éœ€è¿›ä¸€æ­¥æ¢ç´¢
- **å¤šç³»ç»Ÿæ•´åˆ**: éœ€è¦æ›´å…¨é¢çš„ç³»ç»Ÿç”Ÿç‰©å­¦æ–¹æ³•
- **ä¸´åºŠéªŒè¯**: å¤§è§„æ¨¡å‰ç»æ€§ç ”ç©¶ä»ç„¶ä¸è¶³
- **æŠ€æœ¯æ ‡å‡†åŒ–**: AIæ¨¡å‹çš„ä¸´åºŠåº”ç”¨æ ‡å‡†æœ‰å¾…å»ºç«‹

## ğŸ¯ å¯¹ç ”ç©¶è§„åˆ’çš„æŒ‡å¯¼æ„ä¹‰

è¿™{results['literature_count']}ç¯‡æ–‡çŒ®ä¸ºåç»­ç ”ç©¶è§„åˆ’æä¾›äº†åšå®çš„ç†è®ºåŸºç¡€å’ŒæŠ€æœ¯è·¯çº¿æŒ‡å¯¼ï¼Œç¡®ä¿ç ”ç©¶æ–¹å‘çš„ç§‘å­¦æ€§å’Œåˆ›æ–°æ€§ã€‚

---
*æ³¨ï¼šå®Œæ•´æ–‡çŒ®æ•°æ®åº“å·²æœ¬åœ°ä¿å­˜ï¼Œå¯ä¾›æ·±åº¦åˆ†æä½¿ç”¨*
"""
    
    return context

def generate_mock_literature_database() -> List[Dict]:
    """ç”Ÿæˆæ¨¡æ‹Ÿæ–‡çŒ®æ•°æ®åº“ç”¨äºæµ‹è¯•"""
    return [
        {
            'title': 'Artificial Intelligence in DXA Bone Imaging: A Systematic Review',
            'abstract': 'Deep learning models show promise in automated bone density analysis from DXA scans...',
            'journal': 'Nature Medicine',
            'source': 'pubmed',
            'quality_score': 0.95
        },
        {
            'title': 'Bone-Cardiovascular Crosstalk: Role of Osteocalcin in Systemic Health',
            'abstract': 'Emerging evidence suggests bone-derived factors regulate cardiovascular function...',
            'journal': 'New England Journal of Medicine',
            'source': 'pubmed',
            'quality_score': 0.93
        },
        {
            'title': 'Radiomics and Machine Learning in Osteoporosis Prediction',
            'abstract': 'Texture analysis of bone images using ML algorithms improves fracture risk assessment...',
            'journal': 'Radiology',
            'source': 'pubmed',
            'quality_score': 0.88
        },
        {
            'title': 'Deep Learning for Automated Bone Health Assessment from DXA Images',
            'abstract': 'CNN-based approaches demonstrate superior performance in bone mineral density quantification...',
            'journal': 'IEEE Transactions on Medical Imaging',
            'source': 'scholar',
            'quality_score': 0.85
        },
        {
            'title': 'Bone as an Endocrine Organ: Implications for Whole-Body Health',
            'abstract': 'Recent discoveries reveal bone tissue as a major endocrine regulator...',
            'journal': 'Science',
            'source': 'pubmed',
            'quality_score': 0.92
        },
        {
            'title': 'Multi-modal AI for Comprehensive Bone Health Evaluation',
            'abstract': 'Integration of DXA, clinical data, and genetic markers using deep learning...',
            'journal': 'Cell',
            'source': 'pubmed',
            'quality_score': 0.91
        },
        {
            'title': 'Fracture Risk Assessment Using Convolutional Neural Networks',
            'abstract': 'AI models trained on large DXA datasets achieve high accuracy in fracture prediction...',
            'journal': 'The Lancet Digital Health',
            'source': 'pubmed',
            'quality_score': 0.87
        },
        {
            'title': 'Bone Microarchitecture Analysis via Advanced Image Processing',
            'abstract': 'Novel computational methods reveal hidden bone structural patterns...',
            'journal': 'Journal of Bone and Mineral Research',
            'source': 'scholar',
            'quality_score': 0.82
        },
        {
            'title': 'FGF23 and Bone-Kidney-Heart Axis in Health and Disease',
            'abstract': 'Fibroblast growth factor 23 mediates complex organ interactions...',
            'journal': 'Kidney International',
            'source': 'pubmed',
            'quality_score': 0.84
        },
        {
            'title': 'Precision Medicine in Osteoporosis: AI-Driven Personalized Treatment',
            'abstract': 'Machine learning algorithms enable personalized osteoporosis management strategies...',
            'journal': 'Nature Reviews Endocrinology',
            'source': 'pubmed',
            'quality_score': 0.89
        },
        {
            'title': 'Explainable AI for Clinical Decision Support in Bone Health',
            'abstract': 'Interpretable deep learning models provide transparent bone health assessments...',
            'journal': 'Nature Machine Intelligence',
            'source': 'scholar',
            'quality_score': 0.86
        },
        {
            'title': 'Longitudinal Bone Health Monitoring Using Sequential DXA Analysis',
            'abstract': 'Time-series analysis of DXA scans reveals bone health trajectories...',
            'journal': 'Osteoporosis International',
            'source': 'pubmed',
            'quality_score': 0.78
        },
        {
            'title': 'Cross-Modal Learning for Bone Health Assessment',
            'abstract': 'Multi-modal fusion of imaging and laboratory data improves diagnostic accuracy...',
            'journal': 'Medical Image Analysis',
            'source': 'scholar',
            'quality_score': 0.83
        },
        {
            'title': 'Bone Biomarkers and AI: Next-Generation Diagnostics',
            'abstract': 'Integration of biochemical markers with AI models enhances bone health evaluation...',
            'journal': 'Clinical Chemistry',
            'source': 'pubmed',
            'quality_score': 0.81
        },
        {
            'title': 'Federated Learning for Global Bone Health Research',
            'abstract': 'Privacy-preserving machine learning enables large-scale collaborative bone research...',
            'journal': 'Nature Communications',
            'source': 'scholar',
            'quality_score': 0.88
        }
    ] 