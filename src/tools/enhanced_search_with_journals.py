# Copyright (c) 2025 Bytedance Ltd. and/or its affiliates
# SPDX-License-Identifier: MIT

"""
å¢å¼ºæœç´¢æ¥å£ - é›†æˆæœŸåˆŠè´¨é‡æ§åˆ¶
æ”¯æŒæŒ‡å®šé«˜è´¨é‡æœŸåˆŠçš„æ™ºèƒ½æœç´¢å’Œç»“æœè¿‡æ»¤
"""

import logging
from typing import List, Dict, Any, Optional
import asyncio
from concurrent.futures import ThreadPoolExecutor

from .search import (
    get_web_search_tool, 
    get_pubmed_search_tool, 
    get_google_scholar_search_tool
)
from .journal_quality_controller import (
    journal_quality_controller,
    JournalTier,
    JournalInfo,
    get_recommended_journals,
    create_journal_focused_search_query
)

logger = logging.getLogger(__name__)

class JournalAwareSearchEngine:
    """æ”¯æŒæœŸåˆŠè´¨é‡æ§åˆ¶çš„æœç´¢å¼•æ“"""
    
    def __init__(self):
        self.quality_controller = journal_quality_controller
        
    def search_by_journal_quality(
        self, 
        query: str,
        target_tier: str = "high",          # "top", "high", "mid", "all"
        target_field: str = None,           # "ai_ml", "medical_imaging", "bone_health"
        specific_journals: List[str] = None, # æŒ‡å®šæœŸåˆŠåç§°åˆ—è¡¨
        max_results: int = 20,
        engines: List[str] = None           # ["google_scholar", "pubmed", "general"]
    ) -> Dict[str, Any]:
        """
        åŸºäºæœŸåˆŠè´¨é‡è¿›è¡Œæœç´¢
        
        Args:
            query: æœç´¢æŸ¥è¯¢
            target_tier: ç›®æ ‡æœŸåˆŠç­‰çº§
            target_field: ç›®æ ‡ç ”ç©¶é¢†åŸŸ  
            specific_journals: æŒ‡å®šçš„æœŸåˆŠåç§°åˆ—è¡¨
            max_results: æœ€å¤§ç»“æœæ•°
            engines: ä½¿ç”¨çš„æœç´¢å¼•æ“
            
        Returns:
            åŒ…å«é«˜è´¨é‡æ–‡çŒ®çš„æœç´¢ç»“æœ
        """
        
        logger.info(f"ğŸ” å¼€å§‹æœŸåˆŠè´¨é‡å¯¼å‘æœç´¢: {query}")
        logger.info(f"ğŸ“Š æœç´¢å‚æ•°: tier={target_tier}, field={target_field}, journals={specific_journals}")
        
        # 1. ç¡®å®šç›®æ ‡æœŸåˆŠ
        if specific_journals:
            # ä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„æœŸåˆŠ
            target_journals = []
            for journal_name in specific_journals:
                journal_key = journal_name.lower().replace(' ', '_').replace('-', '_')
                journal_info = self.quality_controller.journal_database.get(journal_key)
                if journal_info:
                    target_journals.append(journal_info)
                else:
                    logger.warning(f"âš ï¸ æœªæ‰¾åˆ°æœŸåˆŠä¿¡æ¯: {journal_name}")
        else:
            # æ ¹æ®æŸ¥è¯¢è‡ªåŠ¨æ¨èæœŸåˆŠ
            if target_field:
                tier_map = {
                    "top": JournalTier.TOP_TIER,
                    "high": JournalTier.HIGH_TIER, 
                    "mid": JournalTier.MID_TIER,
                    "all": JournalTier.EMERGING
                }
                min_tier = tier_map.get(target_tier, JournalTier.HIGH_TIER)
                target_journals = self.quality_controller.get_journals_by_field(target_field, min_tier)[:5]
            else:
                target_journals = get_recommended_journals(query, tier=target_tier)[:5]
        
        if not target_journals:
            logger.warning("âš ï¸ æœªæ‰¾åˆ°ç›®æ ‡æœŸåˆŠï¼Œä½¿ç”¨é€šç”¨æœç´¢")
            return self._fallback_search(query, max_results)
        
        logger.info(f"ğŸ¯ é€‰å®šç›®æ ‡æœŸåˆŠ: {[j.name for j in target_journals]}")
        
        # 2. ç”ŸæˆæœŸåˆŠç‰¹å®šçš„æœç´¢æŸ¥è¯¢
        search_strategy = self.quality_controller.get_search_strategy_for_journals(target_journals, query)
        
        # 3. æ‰§è¡Œå¤šå¼•æ“æœç´¢
        if not engines:
            engines = ["google_scholar", "pubmed", "general"]
        
        all_results = []
        search_tasks = []
        
        # ä¸ºæ¯ä¸ªæœŸåˆŠå’Œå¼•æ“ç»„åˆåˆ›å»ºæœç´¢ä»»åŠ¡
        for journal in target_journals[:3]:  # é™åˆ¶ä¸ºå‰3ä¸ªæœŸåˆŠï¼Œé¿å…æŸ¥è¯¢è¿‡å¤š
            journal_queries = search_strategy['multi_engine_queries'].get(journal.name, {})
            
            for engine in engines:
                if engine in journal_queries:
                    search_tasks.append({
                        'engine': engine,
                        'journal': journal.name,
                        'query': journal_queries[engine],
                        'journal_info': journal
                    })
        
        # å¹¶è¡Œæ‰§è¡Œæœç´¢
        results_by_engine = self._execute_parallel_search(search_tasks, max_results)
        
        # 4. ç»“æœè´¨é‡è¿‡æ»¤å’Œæ’åº
        tier_map = {
            "top": JournalTier.TOP_TIER,
            "high": JournalTier.HIGH_TIER,
            "mid": JournalTier.MID_TIER, 
            "all": JournalTier.EMERGING
        }
        min_tier = tier_map.get(target_tier, JournalTier.HIGH_TIER)
        
        filtered_results = self.quality_controller.filter_results_by_journal_quality(
            results_by_engine, min_tier
        )
        
        # 5. æ·»åŠ æœŸåˆŠåŒ¹é…ä¿¡æ¯
        enhanced_results = self._enhance_results_with_journal_info(filtered_results, target_journals)
        
        return {
            'query': query,
            'target_journals': [{'name': j.name, 'impact_factor': j.impact_factor} for j in target_journals],
            'total_results': len(enhanced_results),
            'results': enhanced_results[:max_results],
            'search_strategy': search_strategy
        }
    
    def search_top_tier_only(self, query: str, max_results: int = 10) -> Dict[str, Any]:
        """ä»…æœç´¢é¡¶çº§æœŸåˆŠ (Nature, Science, Cellç­‰)"""
        
        logger.info(f"ğŸ† æ‰§è¡Œé¡¶çº§æœŸåˆŠä¸“é¡¹æœç´¢: {query}")
        
        # è·å–é¡¶çº§æœŸåˆŠ
        top_journals = self.quality_controller.get_top_journals(limit=5)
        
        return self.search_by_journal_quality(
            query=query,
            target_tier="top",
            specific_journals=[j.name for j in top_journals],
            max_results=max_results,
            engines=["google_scholar", "general"]  # é¡¶çº§æœŸåˆŠä¸»è¦ç”¨Google Scholar
        )
    
    def search_by_field_experts(self, query: str, field: str, max_results: int = 15) -> Dict[str, Any]:
        """æŒ‰ä¸“ä¸šé¢†åŸŸæœç´¢ï¼Œä½¿ç”¨è¯¥é¢†åŸŸçš„æƒå¨æœŸåˆŠ"""
        
        logger.info(f"ğŸ”¬ æ‰§è¡Œé¢†åŸŸä¸“å®¶æœç´¢: {query} (é¢†åŸŸ: {field})")
        
        # é¢†åŸŸæœç´¢å¼•æ“ä¼˜åŒ–
        field_engine_map = {
            'medical_imaging': ["google_scholar", "pubmed"],
            'bone_health': ["pubmed", "google_scholar"],
            'ai_ml': ["google_scholar", "general"],
            'cardiovascular': ["pubmed", "google_scholar"]
        }
        
        engines = field_engine_map.get(field, ["google_scholar", "pubmed", "general"])
        
        return self.search_by_journal_quality(
            query=query,
            target_tier="high",
            target_field=field,
            max_results=max_results,
            engines=engines
        )
    
    def _execute_parallel_search(self, search_tasks: List[Dict], max_results: int) -> List[Dict]:
        """å¹¶è¡Œæ‰§è¡Œæœç´¢ä»»åŠ¡"""
        
        all_results = []
        
        with ThreadPoolExecutor(max_workers=min(len(search_tasks), 4)) as executor:
            future_to_task = {}
            
            for task in search_tasks:
                try:
                    # æ ¹æ®å¼•æ“ç±»å‹åˆ›å»ºæœç´¢å·¥å…·
                    if task['engine'] == 'google_scholar':
                        search_tool = get_google_scholar_search_tool()
                        future = executor.submit(search_tool.run, task['query'])
                    elif task['engine'] == 'pubmed':
                        search_tool = get_pubmed_search_tool()
                        future = executor.submit(search_tool.run, task['query'])
                    else:  # general/tavily
                        search_tool = get_web_search_tool(max_results // len(search_tasks))
                        future = executor.submit(search_tool.invoke, task['query'])
                    
                    future_to_task[future] = task
                    
                except Exception as e:
                    logger.error(f"âŒ æœç´¢ä»»åŠ¡åˆ›å»ºå¤±è´¥: {task['engine']} - {e}")
            
            # æ”¶é›†ç»“æœ
            for future in future_to_task:
                task = future_to_task[future]
                try:
                    raw_result = future.result(timeout=30)
                    
                    # è§£ææœç´¢ç»“æœ
                    parsed_results = self._parse_search_result(raw_result, task)
                    all_results.extend(parsed_results)
                    
                    logger.info(f"âœ… {task['engine']} æœç´¢å®Œæˆ: {len(parsed_results)} ä¸ªç»“æœ")
                    
                except Exception as e:
                    logger.warning(f"âš ï¸ {task['engine']} æœç´¢å¤±è´¥: {e}")
        
        return all_results
    
    def _parse_search_result(self, raw_result: Any, task: Dict) -> List[Dict]:
        """è§£æä¸åŒæœç´¢å¼•æ“çš„ç»“æœæ ¼å¼"""
        
        parsed_results = []
        
        try:
            if task['engine'] == 'google_scholar':
                # Google Scholar è¿”å›çš„æ˜¯å­—ç¬¦ä¸²æ ¼å¼
                if isinstance(raw_result, str) and raw_result.strip():
                    # ç®€å•è§£æ Google Scholar ç»“æœ
                    lines = raw_result.split('\n')
                    current_paper = {}
                    
                    for line in lines:
                        line = line.strip()
                        if line.startswith('Title: '):
                            if current_paper:
                                parsed_results.append(current_paper)
                            current_paper = {
                                'title': line.replace('Title: ', ''),
                                'source': 'google_scholar',
                                'journal_source': task['journal'],
                                'content': ''
                            }
                        elif line.startswith('Authors: '):
                            current_paper['authors'] = line.replace('Authors: ', '')
                        elif line.startswith('Summary: '):
                            current_paper['content'] = line.replace('Summary: ', '')
                        elif line.startswith('URL: '):
                            current_paper['url'] = line.replace('URL: ', '')
                    
                    if current_paper:
                        parsed_results.append(current_paper)
            
            elif task['engine'] == 'pubmed':
                # PubMed è¿”å›æ ¼å¼åŒ–çš„å­—ç¬¦ä¸²
                if isinstance(raw_result, str) and 'Result' in raw_result:
                    # è§£æ PubMed ç»“æœ
                    entries = raw_result.split('Result ')
                    for entry in entries[1:]:  # è·³è¿‡ç¬¬ä¸€ä¸ªç©ºæ¡ç›®
                        result_dict = {
                            'source': 'pubmed',
                            'journal_source': task['journal'],
                            'title': '',
                            'content': '',
                            'url': ''
                        }
                        
                        lines = entry.split('\n')
                        for line in lines:
                            if line.strip().startswith('Title: '):
                                result_dict['title'] = line.replace('Title: ', '').strip()
                            elif line.strip().startswith('Abstract Snippet: '):
                                result_dict['content'] = line.replace('Abstract Snippet: ', '').strip()
                            elif line.strip().startswith('URL: '):
                                result_dict['url'] = line.replace('URL: ', '').strip()
                        
                        if result_dict['title']:
                            parsed_results.append(result_dict)
            
            elif isinstance(raw_result, list):
                # Tavily/é€šç”¨æœç´¢è¿”å›åˆ—è¡¨æ ¼å¼
                for item in raw_result:
                    if isinstance(item, dict):
                        result_dict = {
                            'title': item.get('title', ''),
                            'content': item.get('content', ''),
                            'url': item.get('url', ''),
                            'source': task['engine'],
                            'journal_source': task['journal']
                        }
                        parsed_results.append(result_dict)
        
        except Exception as e:
            logger.error(f"âŒ è§£ææœç´¢ç»“æœå¤±è´¥: {task['engine']} - {e}")
        
        return parsed_results
    
    def _enhance_results_with_journal_info(self, results: List[Dict], target_journals: List[JournalInfo]) -> List[Dict]:
        """ä¸ºç»“æœæ·»åŠ æœŸåˆŠä¿¡æ¯å¢å¼º"""
        
        enhanced_results = []
        
        for result in results:
            enhanced_result = result.copy()
            
            # æ·»åŠ ç›®æ ‡æœŸåˆŠåŒ¹é…ä¿¡æ¯
            matched_journal = None
            for journal in target_journals:
                if (journal.name.lower() in result.get('title', '').lower() or 
                    journal.name.lower() in result.get('content', '').lower() or
                    journal.full_name.lower() in result.get('content', '').lower()):
                    matched_journal = journal
                    break
            
            if matched_journal:
                enhanced_result['matched_journal'] = {
                    'name': matched_journal.name,
                    'full_name': matched_journal.full_name,
                    'impact_factor': matched_journal.impact_factor,
                    'tier': matched_journal.tier.value
                }
                enhanced_result['quality_score'] = self._calculate_quality_score(result, matched_journal)
            
            enhanced_results.append(enhanced_result)
        
        # æŒ‰è´¨é‡åˆ†æ•°æ’åº
        enhanced_results.sort(key=lambda r: r.get('quality_score', 0), reverse=True)
        
        return enhanced_results
    
    def _calculate_quality_score(self, result: Dict, journal: JournalInfo) -> float:
        """è®¡ç®—ç»“æœè´¨é‡åˆ†æ•°"""
        
        base_score = 0.5
        
        # æœŸåˆŠå½±å“å› å­åŠ æƒ
        if journal.impact_factor > 20:
            base_score += 0.4
        elif journal.impact_factor > 10:
            base_score += 0.3
        elif journal.impact_factor > 5:
            base_score += 0.2
        else:
            base_score += 0.1
        
        # æœŸåˆŠç­‰çº§åŠ æƒ
        tier_bonus = {
            JournalTier.TOP_TIER: 0.3,
            JournalTier.HIGH_TIER: 0.2,
            JournalTier.MID_TIER: 0.1,
            JournalTier.EMERGING: 0.0
        }
        base_score += tier_bonus.get(journal.tier, 0)
        
        # å†…å®¹è´¨é‡è¯„ä¼°
        content_length = len(result.get('content', ''))
        if content_length > 500:
            base_score += 0.1
        
        return min(base_score, 1.0)
    
    def _fallback_search(self, query: str, max_results: int) -> Dict[str, Any]:
        """é™çº§æœç´¢ç­–ç•¥"""
        
        logger.info("ğŸ”„ æ‰§è¡Œé™çº§æœç´¢ç­–ç•¥")
        
        try:
            # ä½¿ç”¨é€šç”¨æœç´¢å·¥å…·
            web_tool = get_web_search_tool(max_results)
            results = web_tool.invoke(query)
            
            if isinstance(results, list):
                return {
                    'query': query,
                    'total_results': len(results),
                    'results': results,
                    'search_strategy': 'fallback'
                }
        except Exception as e:
            logger.error(f"âŒ é™çº§æœç´¢ä¹Ÿå¤±è´¥äº†: {e}")
        
        return {
            'query': query,
            'total_results': 0,
            'results': [],
            'search_strategy': 'failed'
        }

# åˆ›å»ºå…¨å±€å®ä¾‹
journal_aware_search_engine = JournalAwareSearchEngine()

# ä¾¿æ·æ¥å£å‡½æ•°
def search_high_quality_journals(query: str, field: str = None, max_results: int = 15) -> Dict[str, Any]:
    """æœç´¢é«˜è´¨é‡æœŸåˆŠæ–‡çŒ®"""
    return journal_aware_search_engine.search_by_journal_quality(
        query=query,
        target_tier="high",
        target_field=field,
        max_results=max_results
    )

def search_top_tier_journals_only(query: str, max_results: int = 10) -> Dict[str, Any]:
    """ä»…æœç´¢é¡¶çº§æœŸåˆŠ (Nature, Science, Cellç­‰)"""
    return journal_aware_search_engine.search_top_tier_only(query, max_results)

def search_specific_journals(query: str, journals: List[str], max_results: int = 20) -> Dict[str, Any]:
    """æœç´¢æŒ‡å®šæœŸåˆŠåˆ—è¡¨"""
    return journal_aware_search_engine.search_by_journal_quality(
        query=query,
        specific_journals=journals,
        max_results=max_results
    ) 