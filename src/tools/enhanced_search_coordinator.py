# Copyright (c) 2025 Bytedance Ltd. and/or its affiliates
# SPDX-License-Identifier: MIT

"""
å¢å¼ºæœç´¢åè°ƒå™¨ - æ™ºèƒ½é€‰æ‹©æœ€ä½³æœç´¢ç­–ç•¥
å®ç°å¤šå¼•æ“å¹¶è¡Œæœç´¢ã€è´¨é‡è¿‡æ»¤ã€ä¸­è‹±æ–‡ä¼˜åŒ–
"""

import asyncio
import logging
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass
from concurrent.futures import ThreadPoolExecutor, as_completed
import time

from .search import (
    LoggedTavilySearch, 
    LoggedPubMedSearch, 
    LoggedGoogleScholarSearch,
    LoggedDuckDuckGoSearch
)

logger = logging.getLogger(__name__)

@dataclass
class SearchResult:
    """æ ‡å‡†åŒ–æœç´¢ç»“æœæ ¼å¼"""
    title: str
    content: str
    url: str
    source: str  # æœç´¢å¼•æ“åç§°
    quality_score: float  # è´¨é‡è¯„åˆ† 0-1
    relevance_score: float  # ç›¸å…³æ€§è¯„åˆ† 0-1
    is_academic: bool  # æ˜¯å¦å­¦æœ¯æ–‡çŒ®
    publish_year: Optional[int] = None
    impact_factor: Optional[float] = None

@dataclass
class SearchStrategy:
    """æœç´¢ç­–ç•¥é…ç½®"""
    query_type: str  # "general", "academic", "medical", "technical"
    languages: List[str]  # ["en", "zh", "mixed"]
    engines: List[str]  # ä½¿ç”¨çš„æœç´¢å¼•æ“
    max_results_per_engine: int
    quality_threshold: float
    parallel_search: bool

class EnhancedSearchCoordinator:
    """å¢å¼ºæœç´¢åè°ƒå™¨"""
    
    def __init__(self):
        self.engines = {
            'tavily': LoggedTavilySearch,
            'pubmed': LoggedPubMedSearch,
            'google_scholar': LoggedGoogleScholarSearch,
            'duckduckgo': LoggedDuckDuckGoSearch
        }
        
        # é¢„å®šä¹‰æœç´¢ç­–ç•¥
        self.strategies = {
            'medical_research': SearchStrategy(
                query_type="medical",
                languages=["en", "zh"],
                engines=["pubmed", "google_scholar", "tavily"],
                max_results_per_engine=10,
                quality_threshold=0.7,
                parallel_search=True
            ),
            'ai_technology': SearchStrategy(
                query_type="technical", 
                languages=["en"],
                engines=["google_scholar", "tavily"],
                max_results_per_engine=15,
                quality_threshold=0.6,
                parallel_search=True
            ),
            'general_research': SearchStrategy(
                query_type="general",
                languages=["en", "zh"],
                engines=["tavily", "duckduckgo"],
                max_results_per_engine=8,
                quality_threshold=0.5,
                parallel_search=False
            ),
            'comprehensive_survey': SearchStrategy(
                query_type="academic",
                languages=["en", "zh"],
                engines=["pubmed", "google_scholar", "tavily"],
                max_results_per_engine=20,
                quality_threshold=0.8,
                parallel_search=True
            )
        }
    
    def select_strategy(self, query: str, context: Dict[str, Any] = None) -> SearchStrategy:
        """æ™ºèƒ½é€‰æ‹©æœç´¢ç­–ç•¥"""
        
        # åŸºäºæŸ¥è¯¢å†…å®¹çš„å…³é”®è¯æ£€æµ‹
        medical_keywords = ['dxa', 'medical', 'clinical', 'patient', 'disease', 'therapy', 'drug']
        ai_keywords = ['ai', 'machine learning', 'deep learning', 'neural network', 'algorithm']
        academic_keywords = ['research', 'study', 'analysis', 'methodology', 'systematic review']
        
        query_lower = query.lower()
        
        # æ£€æµ‹ä¸­æ–‡å†…å®¹
        has_chinese = any('\u4e00' <= char <= '\u9fff' for char in query)
        
        # æ™ºèƒ½ç­–ç•¥é€‰æ‹©
        if any(keyword in query_lower for keyword in medical_keywords):
            strategy = self.strategies['medical_research'].copy() if hasattr(self.strategies['medical_research'], 'copy') else self.strategies['medical_research']
            logger.info("ğŸ” é€‰æ‹©åŒ»å­¦ç ”ç©¶æœç´¢ç­–ç•¥")
            
        elif any(keyword in query_lower for keyword in ai_keywords):
            strategy = self.strategies['ai_technology']
            logger.info("ğŸ” é€‰æ‹©AIæŠ€æœ¯æœç´¢ç­–ç•¥")
            
        elif any(keyword in query_lower for keyword in academic_keywords) or (context and context.get('is_comprehensive')):
            strategy = self.strategies['comprehensive_survey']
            logger.info("ğŸ” é€‰æ‹©ç»¼åˆå­¦æœ¯æœç´¢ç­–ç•¥")
            
        else:
            strategy = self.strategies['general_research']
            logger.info("ğŸ” é€‰æ‹©é€šç”¨ç ”ç©¶æœç´¢ç­–ç•¥")
        
        # å¦‚æœæœ‰ä¸­æ–‡å†…å®¹ï¼Œç¡®ä¿åŒ…å«ä¸­æ–‡æœç´¢
        if has_chinese and "zh" not in strategy.languages:
            strategy.languages.append("zh")
        
        return strategy
    
    def optimize_query(self, query: str, language: str, engine: str) -> str:
        """é’ˆå¯¹ä¸åŒå¼•æ“å’Œè¯­è¨€ä¼˜åŒ–æŸ¥è¯¢è¯­å¥"""
        
        optimized_queries = {
            'en': {
                'pubmed': f"({query}) AND (systematic review OR meta-analysis OR clinical trial)",
                'google_scholar': f'"{query}" systematic review OR methodology',
                'tavily': f"{query} latest research findings",
                'duckduckgo': query
            },
            'zh': {
                'tavily': f"{query} æœ€æ–°ç ”ç©¶",
                'duckduckgo': f"{query} ç ”ç©¶ ç»¼è¿°",
                'google_scholar': f"{query} ç³»ç»Ÿæ€§ç»¼è¿°",
                'pubmed': query  # PubMedä¸»è¦è‹±æ–‡ï¼Œä¿æŒåŸæŸ¥è¯¢
            }
        }
        
        return optimized_queries.get(language, {}).get(engine, query)
    
    def assess_result_quality(self, result: Dict[str, Any], source: str) -> float:
        """è¯„ä¼°æœç´¢ç»“æœè´¨é‡"""
        
        quality_score = 0.5  # åŸºç¡€åˆ†æ•°
        
        # æ¥æºæƒé‡
        source_weights = {
            'pubmed': 0.9,
            'google_scholar': 0.8,
            'tavily': 0.6,
            'duckduckgo': 0.5
        }
        quality_score *= source_weights.get(source, 0.5)
        
        # æ ‡é¢˜è´¨é‡æ£€æŸ¥
        title = result.get('title', '').lower()
        if any(keyword in title for keyword in ['systematic review', 'meta-analysis', 'clinical trial']):
            quality_score += 0.2
        if any(keyword in title for keyword in ['2023', '2024', 'recent', 'latest']):
            quality_score += 0.1
            
        # å†…å®¹é•¿åº¦æ£€æŸ¥
        content = result.get('content', '')
        if len(content) > 500:
            quality_score += 0.1
        if len(content) > 1000:
            quality_score += 0.1
            
        # URLè´¨é‡æ£€æŸ¥
        url = result.get('url', '').lower()
        quality_domains = [
            'pubmed.ncbi.nlm.nih.gov', 'scholar.google.com', 'arxiv.org',
            'nature.com', 'cell.com', 'science.org', 'nejm.org', 'thelancet.com'
        ]
        if any(domain in url for domain in quality_domains):
            quality_score += 0.2
            
        return min(quality_score, 1.0)  # ç¡®ä¿ä¸è¶…è¿‡1.0
    
    async def parallel_search(self, strategy: SearchStrategy, query: str) -> List[SearchResult]:
        """å¹¶è¡Œæ‰§è¡Œå¤šå¼•æ“æœç´¢"""
        
        results = []
        search_tasks = []
        
        # ä¸ºæ¯ä¸ªå¼•æ“å’Œè¯­è¨€åˆ›å»ºæœç´¢ä»»åŠ¡
        for engine in strategy.engines:
            for language in strategy.languages:
                optimized_query = self.optimize_query(query, language, engine)
                
                if engine in self.engines:
                    try:
                        engine_instance = self.engines[engine]()
                        search_tasks.append({
                            'engine': engine,
                            'language': language, 
                            'query': optimized_query,
                            'instance': engine_instance
                        })
                    except Exception as e:
                        logger.warning(f"âš ï¸ æ— æ³•åˆå§‹åŒ–æœç´¢å¼•æ“ {engine}: {e}")
        
        # å¹¶è¡Œæ‰§è¡Œæœç´¢
        with ThreadPoolExecutor(max_workers=min(len(search_tasks), 5)) as executor:
            future_to_task = {}
            
            for task in search_tasks:
                try:
                    future = executor.submit(
                        task['instance'].invoke,
                        {'query': task['query']} if isinstance(task['query'], str) else task['query']
                    )
                    future_to_task[future] = task
                except Exception as e:
                    logger.error(f"âŒ æœç´¢ä»»åŠ¡æäº¤å¤±è´¥ {task['engine']}: {e}")
            
            # æ”¶é›†ç»“æœ
            for future in as_completed(future_to_task, timeout=30):
                task = future_to_task[future]
                try:
                    raw_results = future.result(timeout=10)
                    
                    # æ ‡å‡†åŒ–ç»“æœæ ¼å¼
                    if isinstance(raw_results, list):
                        for item in raw_results:
                            if isinstance(item, dict):
                                quality_score = self.assess_result_quality(item, task['engine'])
                                
                                if quality_score >= strategy.quality_threshold:
                                    result = SearchResult(
                                        title=item.get('title', ''),
                                        content=item.get('content', ''),
                                        url=item.get('url', ''),
                                        source=task['engine'],
                                        quality_score=quality_score,
                                        relevance_score=0.5,  # å¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–
                                        is_academic=task['engine'] in ['pubmed', 'google_scholar']
                                    )
                                    results.append(result)
                                    
                except Exception as e:
                    logger.warning(f"âš ï¸ æœç´¢å¼•æ“ {task['engine']} æ‰§è¡Œå¤±è´¥: {e}")
        
        # ç»“æœå»é‡å’Œæ’åº
        unique_results = self.deduplicate_results(results)
        sorted_results = sorted(unique_results, 
                               key=lambda x: (x.quality_score + x.relevance_score) / 2, 
                               reverse=True)
        
        logger.info(f"âœ… å¹¶è¡Œæœç´¢å®Œæˆï¼Œè·å¾— {len(sorted_results)} ä¸ªé«˜è´¨é‡ç»“æœ")
        return sorted_results[:strategy.max_results_per_engine * len(strategy.engines)]
    
    def deduplicate_results(self, results: List[SearchResult]) -> List[SearchResult]:
        """ç»“æœå»é‡"""
        seen_urls = set()
        seen_titles = set()
        unique_results = []
        
        for result in results:
            # åŸºäºURLå»é‡
            if result.url and result.url in seen_urls:
                continue
            # åŸºäºæ ‡é¢˜å»é‡ï¼ˆè€ƒè™‘ç›¸ä¼¼æ€§ï¼‰
            title_key = result.title.lower().strip()
            if title_key and title_key in seen_titles:
                continue
                
            seen_urls.add(result.url)
            seen_titles.add(title_key)
            unique_results.append(result)
        
        return unique_results
    
    async def enhanced_search(self, query: str, context: Dict[str, Any] = None) -> List[Dict[str, Any]]:
        """å¢å¼ºæœç´¢ä¸»å…¥å£"""
        
        start_time = time.time()
        
        # é€‰æ‹©æœç´¢ç­–ç•¥
        strategy = self.select_strategy(query, context)
        logger.info(f"ğŸ” æœç´¢ç­–ç•¥: {strategy.query_type}, å¼•æ“: {strategy.engines}, è¯­è¨€: {strategy.languages}")
        
        # æ‰§è¡Œæœç´¢
        if strategy.parallel_search:
            results = await self.parallel_search(strategy, query)
        else:
            # ä¸²è¡Œæœç´¢ï¼ˆä¿ç•™å‘åå…¼å®¹ï¼‰
            results = []
            for engine in strategy.engines:
                try:
                    engine_instance = self.engines[engine]()
                    raw_results = engine_instance.invoke(query)
                    # å¤„ç†ç»“æœ...
                except Exception as e:
                    logger.warning(f"âš ï¸ ä¸²è¡Œæœç´¢å¤±è´¥ {engine}: {e}")
        
        # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
        formatted_results = []
        for result in results:
            formatted_results.append({
                'title': result.title,
                'content': result.content,
                'url': result.url,
                'source': result.source,
                'quality_score': result.quality_score,
                'is_academic': result.is_academic
            })
        
        elapsed_time = time.time() - start_time
        logger.info(f"âœ… å¢å¼ºæœç´¢å®Œæˆï¼Œè€—æ—¶ {elapsed_time:.2f}sï¼Œè·å¾— {len(formatted_results)} ä¸ªç»“æœ")
        
        return formatted_results

# åˆ›å»ºå…¨å±€å®ä¾‹
enhanced_search_coordinator = EnhancedSearchCoordinator() 