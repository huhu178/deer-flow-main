"""
å¢å¼ºæœç´¢å·¥å…· - ç»“åˆSerpAPIå®æ—¶æœç´¢ä¸ç°æœ‰æœç´¢èƒ½åŠ›
"""
import os
import logging
from typing import Dict, List, Any
from datetime import datetime

logger = logging.getLogger(__name__)

# SerpAPIå¯¼å…¥
try:
    from serpapi import GoogleSearch
    SERPAPI_AVAILABLE = True
    logger.info("âœ… SerpAPIå¯ç”¨")
except ImportError:
    SERPAPI_AVAILABLE = False
    logger.warning("âš ï¸ SerpAPIä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨å¤‡ç”¨æœç´¢æ–¹æ¡ˆ")

def enhanced_real_time_search(query: str, num_results: int = 10) -> Dict[str, Any]:
    """å¢å¼ºçš„å®æ—¶æœç´¢ - ä¼˜å…ˆä½¿ç”¨SerpAPIï¼Œå¤‡ç”¨Tavily"""
    
    if SERPAPI_AVAILABLE:
        try:
            api_key = os.getenv("SERPAPI_API_KEY")
            if not api_key:
                raise ValueError("SerpAPI APIå¯†é’¥æœªé…ç½®")
            
            search_params = {
                "q": query,
                "api_key": api_key,
                "engine": "google",
                "location": "China",
                "num": num_results,
                "google_domain": "google.com",
                "gl": "cn",
                "hl": "zh-cn",
            }
            
            search = GoogleSearch(search_params)
            results = search.get_dict()
            
            organic_results = results.get("organic_results", [])
            processed_results = []
            sources = []
            
            for i, result in enumerate(organic_results):
                title = result.get("title", "")
                link = result.get("link", "")
                snippet = result.get("snippet", "")
                
                processed_results.append({
                    "type": "organic",
                    "title": title,
                    "url": link,
                    "content": snippet,
                    "relevance_score": 0.9 - (i * 0.1)
                })
                
                sources.append({
                    "label": title[:60] + "..." if len(title) > 60 else title,
                    "url": link,
                    "type": "web"
                })
            
            summary = generate_search_summary(query, processed_results)
            
            return {
                "status": "success",
                "source": "SerpAPI",
                "query": query,
                "results_count": len(processed_results),
                "results": processed_results,
                "sources": sources,
                "summary": summary,
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"SerpAPIæœç´¢å¤±è´¥: {str(e)}")
            return fallback_search(query, num_results, error=str(e))
    
    else:
        return fallback_search(query, num_results)


def fallback_search(query: str, num_results: int, error: str = None) -> Dict[str, Any]:
    """å¤‡ç”¨æœç´¢æ–¹æ¡ˆ"""
    try:
        from src.tools.tavily_search.tavily_search_tool import search_web
        tavily_results = search_web(query)
        
        processed_results = []
        sources = []
        
        if isinstance(tavily_results, list):
            for i, result in enumerate(tavily_results[:num_results]):
                if isinstance(result, dict):
                    processed_results.append({
                        "type": "web",
                        "title": result.get("title", ""),
                        "url": result.get("url", ""),
                        "content": result.get("content", ""),
                        "relevance_score": 0.8 - (i * 0.05)
                    })
                    
                    sources.append({
                        "label": result.get("title", "")[:60] + "...",
                        "url": result.get("url", ""),
                        "type": "web"
                    })
        
        summary = generate_search_summary(query, processed_results)
        
        return {
            "status": "fallback",
            "source": "Tavily",
            "query": query,
            "results_count": len(processed_results),
            "results": processed_results,
            "sources": sources,
            "summary": summary,
            "timestamp": datetime.now().isoformat(),
            "fallback_reason": error or "SerpAPIä¸å¯ç”¨"
        }
        
    except Exception as e:
        logger.error(f"å¤‡ç”¨æœç´¢ä¹Ÿå¤±è´¥: {str(e)}")
        return {
            "status": "error",
            "query": query,
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }


def generate_search_summary(query: str, results: List[Dict]) -> str:
    """åŸºäºæœç´¢ç»“æœç”Ÿæˆæ™ºèƒ½æ‘˜è¦"""
    if not results:
        return f"æœªæ‰¾åˆ°å…³äº'{query}'çš„ç›¸å…³ä¿¡æ¯ã€‚"
    
    sorted_results = sorted(results, key=lambda x: x.get("relevance_score", 0), reverse=True)
    top_results = sorted_results[:3]
    
    summary = f"ğŸ” **æœç´¢æ‘˜è¦ï¼š{query}**\n\nğŸ“Š æ‰¾åˆ°{len(results)}ä¸ªç›¸å…³ç»“æœ\n\nğŸ¯ **æ ¸å¿ƒå‘ç°**ï¼š\n"
    
    for i, result in enumerate(top_results, 1):
        title = result.get("title", "")[:80]
        content = result.get("content", "")[:150]
        summary += f"\n{i}. **{title}**\n   {content}...\n"
    
    return summary


# å¯¼å‡ºä¸»è¦å‡½æ•°
__all__ = ["enhanced_real_time_search", "generate_search_summary"]
