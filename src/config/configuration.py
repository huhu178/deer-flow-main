# Copyright (c) 2025 Bytedance Ltd. and/or its affiliates
# SPDX-License-Identifier: MIT

import os
from dataclasses import dataclass, fields
from typing import Any, Optional, Dict
import yaml
from pathlib import Path

from langchain_core.runnables import RunnableConfig


@dataclass(kw_only=True)
class Configuration:
    """The configurable fields."""

    # ðŸ”§ ä¼˜åŒ–åŽçš„é…ç½®å‚æ•° - å¤§å¹…å¢žåŠ æœç´¢ç»“æžœ
    max_plan_iterations: int = 1  # Maximum number of plan iterations
    max_step_num: int = 5  # å¢žåŠ æ­¥éª¤æ•°é‡ï¼ˆä»Ž3å¢žåŠ åˆ°5ï¼‰
    max_search_results: int = 12  # ðŸ” å¤§å¹…å¢žåŠ æœç´¢ç»“æžœï¼ˆä»Ž3å¢žåŠ åˆ°12ï¼‰
    mcp_settings: dict = None  # MCP settings, including dynamic loaded tools
    
    # ðŸ”„ å¤šè½®äº¤äº’é…ç½®å‚æ•° - ä¸ä¾èµ–è´¨é‡é˜ˆå€¼åˆ¤æ–­
    max_understanding_rounds: int = 5     # ðŸ”§ ç†è§£é˜¶æ®µæœ€å¤š5è½®æ·±å…¥äº¤äº’
    max_planning_rounds: int = 3          # ðŸ”§ è§„åˆ’é˜¶æ®µæœ€å¤š3è½®è¿­ä»£ä¼˜åŒ–
    understanding_quality_threshold: float = 0.0  # ðŸ”§ ç¦ç”¨ç†è§£è´¨é‡é˜ˆå€¼åˆ¤æ–­
    planning_quality_threshold: float = 0.0       # ðŸ”§ ç¦ç”¨è§„åˆ’è´¨é‡é˜ˆå€¼åˆ¤æ–­
    enable_deep_thinking: bool = True     # ðŸ”§ å¯ç”¨æ·±åº¦æ€è€ƒ
    enable_progressive_planning: bool = True  # ðŸ”§ å¯ç”¨æ¸è¿›å¼è§„åˆ’
    thinking_time_seconds: float = 2.0    # ðŸ”§ æ€è€ƒæ—¶é—´2ç§’
    auto_clarification: bool = True       # ðŸ”§ å¯ç”¨è‡ªåŠ¨æ¾„æ¸…
    
    # ðŸŽ¯ ç®€åŒ–çš„äº¤äº’æ¨¡å¼æŽ§åˆ¶
    interaction_mode: str = "enhanced"    # ðŸ”§ é»˜è®¤ä½¿ç”¨å¢žå¼ºæ¨¡å¼
    # - standard: åŽŸæœ‰æ¨¡å¼ (1è½®ç†è§£ + 1è½®è§„åˆ’)  
    # - enhanced: å¢žå¼ºæ¨¡å¼ (å¤šè½®ç†è§£ + å¤šè½®è§„åˆ’)
    # - auto: è‡ªåŠ¨æ¨¡å¼ (æ ¹æ®å¤æ‚åº¦åŠ¨æ€è°ƒæ•´)
    
    # ðŸ” æ–°å¢žï¼šæœç´¢ç­–ç•¥é…ç½®
    enable_multi_source_search: bool = True    # å¯ç”¨å¤šæºæœç´¢
    pubmed_max_results: int = 10              # PubMedæœ€å¤§ç»“æžœæ•°
    scholar_max_results: int = 10             # Google Scholaræœ€å¤§ç»“æžœæ•°
    arxiv_max_results: int = 8                # ArXivæœ€å¤§ç»“æžœæ•°

    @classmethod
    def from_runnable_config(
        cls, config: Optional[RunnableConfig] = None
    ) -> "Configuration":
        """Create a Configuration instance from a RunnableConfig."""
        configurable = (
            config["configurable"] if config and "configurable" in config else {}
        )
        values: dict[str, Any] = {
            f.name: os.environ.get(f.name.upper(), configurable.get(f.name))
            for f in fields(cls)
            if f.init
        }
        return cls(**{k: v for k, v in values.items() if v})

    def get_understanding_config(self) -> dict:
        """èŽ·å–ç†è§£é˜¶æ®µçš„é…ç½®å‚æ•°"""
        return {
            "max_rounds": self.max_understanding_rounds,
            "quality_threshold": self.understanding_quality_threshold,
            "enable_deep_thinking": self.enable_deep_thinking,
            "thinking_time": self.thinking_time_seconds,
            "auto_clarification": self.auto_clarification
        }
    
    def get_planning_config(self) -> dict:
        """èŽ·å–è§„åˆ’é˜¶æ®µçš„é…ç½®å‚æ•°"""
        return {
            "max_rounds": self.max_planning_rounds,
            "quality_threshold": self.planning_quality_threshold,
            "enable_progressive": self.enable_progressive_planning,
            "thinking_time": self.thinking_time_seconds
        }
    
    def should_use_enhanced_mode(self) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥ä½¿ç”¨å¢žå¼ºäº¤äº’æ¨¡å¼"""
        return self.interaction_mode in ["enhanced", "auto"]
    
    def get_total_max_iterations(self) -> int:
        """èŽ·å–æ€»çš„æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼ˆç†è§£ + è§„åˆ’ï¼‰"""
        if self.interaction_mode == "enhanced":
            return self.max_understanding_rounds + self.max_planning_rounds
        elif self.interaction_mode == "auto":
            return max(3, self.max_understanding_rounds + self.max_planning_rounds)
        else:
            return self.max_plan_iterations  # æ ‡å‡†æ¨¡å¼


def get_current_model_name() -> str:
    """
    èŽ·å–å½“å‰ä½¿ç”¨çš„æ¨¡åž‹åç§°ï¼Œç”¨äºŽæ–‡ä»¶å‘½å
    
    ä¼˜å…ˆçº§ï¼š
    1. çŽ¯å¢ƒå˜é‡ CURRENT_MODEL
    2. conf.yaml ä¸­çš„ MODEL_SWITCH.primary_model é…ç½®
    3. é…ç½®æ–‡ä»¶ model_name.txt
    4. é»˜è®¤å€¼ "gemini"
    
    Returns:
        str: æ¨¡åž‹åç§°ï¼Œç”¨äºŽæ–‡ä»¶å‘½å
    """
    # 1. æ£€æŸ¥çŽ¯å¢ƒå˜é‡
    model_from_env = os.environ.get('CURRENT_MODEL')
    if model_from_env:
        return model_from_env.strip()
    
    # 2. ä»Žconf.yamlè¯»å–é…ç½®
    try:
        conf_file = os.path.join(os.path.dirname(__file__), '..', '..', 'conf.yaml')
        if os.path.exists(conf_file):
            with open(conf_file, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            
            # ðŸŽ¯ ä¼˜å…ˆä»ŽFILE_NAMING.model_nameè¯»å–ï¼ˆæœ€ç›´æŽ¥çš„é…ç½®ï¼‰
            file_naming_model = config.get('FILE_NAMING', {}).get('model_name', '')
            if file_naming_model:
                return file_naming_model.strip()
                
            # å¤‡ç”¨ï¼šä»ŽMODEL_SWITCH.primary_modelèŽ·å–é…ç½®key
            primary_model = config.get('MODEL_SWITCH', {}).get('primary_model', '')
            
            # å°†é…ç½®keyè½¬æ¢ä¸ºæ¨¡åž‹åç§°
            model_name_mapping = {
                'BASIC_MODEL': 'gemini',
                'DEEPSEEK_MODEL': 'deepseek', 
                'QIANWEN_MODEL': 'qianwen'
            }
            
            if primary_model in model_name_mapping:
                return model_name_mapping[primary_model]
    except Exception as e:
        print(f"âš ï¸  è¯»å–conf.yamlå¤±è´¥: {e}")
    
    # 3. æ£€æŸ¥é…ç½®æ–‡ä»¶
    try:
        config_file = os.path.join(os.path.dirname(__file__), 'model_name.txt')
        if os.path.exists(config_file):
            with open(config_file, 'r', encoding='utf-8') as f:
                model_from_file = f.read().strip()
                if model_from_file:
                    return model_from_file
    except Exception:
        pass
    
    # 4. é»˜è®¤å€¼
    return "gemini"


def set_current_model_name(model_name: str) -> None:
    """
    è®¾ç½®å½“å‰ä½¿ç”¨çš„æ¨¡åž‹åç§°
    
    Args:
        model_name: æ¨¡åž‹åç§° (å¦‚: "gemini", "deepseek", "qwen" ç­‰)
    """
    # æ–¹æ³•1ï¼šä¼˜å…ˆä¿®æ”¹conf.yaml
    try:
        update_conf_yaml_model(model_name)
        print(f"âœ… å·²åœ¨conf.yamlä¸­è®¾ç½®æ¨¡åž‹ä¸º: {model_name}")
    except Exception as e:
        print(f"âš ï¸  æ— æ³•ä¿®æ”¹conf.yaml: {e}")
        # æ–¹æ³•2ï¼šé™çº§åˆ°é…ç½®æ–‡ä»¶
        try:
            config_file = os.path.join(os.path.dirname(__file__), 'model_name.txt')
            with open(config_file, 'w', encoding='utf-8') as f:
                f.write(model_name.strip())
            print(f"âœ… å·²åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½®æ¨¡åž‹ä¸º: {model_name}")
        except Exception as e2:
            print(f"âŒ è®¾ç½®æ¨¡åž‹åç§°å¤±è´¥: {e2}")
            return
    
    print(f"ðŸ“ æ–‡ä»¶å°†ä¿å­˜åˆ°: outputs/batch_directions_{model_name} å’Œ outputs/complete_reports_{model_name}")


def update_conf_yaml_model(model_name: str) -> None:
    """
    æ›´æ–°conf.yamlä¸­çš„æ¨¡åž‹é…ç½®
    
    Args:
        model_name: æ¨¡åž‹åç§° (å¦‚: "gemini", "deepseek", "qwen", "doubao")
    """
    conf_file = os.path.join(os.path.dirname(__file__), '..', '..', 'conf.yaml')
    
    # è¯»å–é…ç½®
    with open(conf_file, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    # æ›´æ–°MODEL_SWITCH.primary_model
    if 'MODEL_SWITCH' not in config:
        config['MODEL_SWITCH'] = {}
    
    config['MODEL_SWITCH']['primary_model'] = model_name.lower()
    
    # ðŸ”§ åŒæ—¶æ›´æ–°FILE_NAMING.model_name
    if 'FILE_NAMING' not in config:
        config['FILE_NAMING'] = {}
    config['FILE_NAMING']['model_name'] = model_name.lower()
    
    # å†™å›žæ–‡ä»¶
    with open(conf_file, 'w', encoding='utf-8') as f:
        yaml.dump(config, f, default_flow_style=False, allow_unicode=True, sort_keys=False)


def list_available_models() -> list:
    """
    åˆ—å‡ºå¯ç”¨çš„æ¨¡åž‹åç§°å»ºè®®
    
    Returns:
        list: å¸¸ç”¨æ¨¡åž‹åç§°åˆ—è¡¨
    """
    return [
        "gemini",      # Google Gemini
        "doubao",      # å­—èŠ‚è±†åŒ…
        "deepseek",    # DeepSeek
        "qwen",        # é˜¿é‡Œé€šä¹‰åƒé—®
        "chatgpt",     # OpenAI ChatGPT
        "claude",      # Anthropic Claude
        "llama",       # Meta LLaMA
        "yi",          # é›¶ä¸€ä¸‡ç‰©
        "baichuan",    # ç™¾å·æ™ºèƒ½
        "custom"       # è‡ªå®šä¹‰æ¨¡åž‹
    ]


def get_model_output_info() -> dict:
    """
    èŽ·å–å½“å‰æ¨¡åž‹çš„è¾“å‡ºä¿¡æ¯
    
    Returns:
        dict: åŒ…å«æ¨¡åž‹åç§°å’Œè¾“å‡ºç›®å½•çš„ä¿¡æ¯
    """
    current_model = get_current_model_name()
    return {
        "model_name": current_model,
        "batch_directions_dir": f"outputs/batch_directions_{current_model}",
        "complete_reports_dir": f"outputs/complete_reports_{current_model}",
        "config_file": os.path.join(os.path.dirname(__file__), 'model_name.txt')
    }


# ðŸ”„ å¤šè½®äº¤äº’é…ç½®é¢„è®¾
class InteractionPresets:
    """å¤šè½®äº¤äº’é…ç½®é¢„è®¾"""
    
    @staticmethod
    def get_standard_config() -> Configuration:
        """æ ‡å‡†é…ç½® - ä¸ŽåŽŸæœ‰ç³»ç»Ÿä¿æŒä¸€è‡´"""
        return Configuration(
            max_plan_iterations=1,
            interaction_mode="standard",
            max_understanding_rounds=1,
            max_planning_rounds=1
        )
    
    @staticmethod
    def get_enhanced_config() -> Configuration:
        """å¢žå¼ºé…ç½® - æ”¯æŒå¤šè½®æ·±åº¦äº¤äº’"""
        return Configuration(
            max_plan_iterations=5,  # å…¼å®¹åŽŸæœ‰å‚æ•°
            interaction_mode="enhanced",
            max_understanding_rounds=5,
            max_planning_rounds=3,
            understanding_quality_threshold=0.8,
            planning_quality_threshold=0.8,
            enable_deep_thinking=True,
            thinking_time_seconds=1.0
        )
    
    @staticmethod  
    def get_auto_config() -> Configuration:
        """è‡ªåŠ¨é…ç½® - æ ¹æ®é—®é¢˜å¤æ‚åº¦åŠ¨æ€è°ƒæ•´"""
        return Configuration(
            max_plan_iterations=3,
            interaction_mode="auto",
            max_understanding_rounds=3,
            max_planning_rounds=2,
            understanding_quality_threshold=0.7,
            planning_quality_threshold=0.7,
            enable_deep_thinking=True,
            thinking_time_seconds=0.5
        )
    
    @staticmethod
    def get_fast_config() -> Configuration:
        """å¿«é€Ÿé…ç½® - æœ€å°äº¤äº’ï¼Œå¿«é€Ÿå“åº”"""
        return Configuration(
            max_plan_iterations=1,
            interaction_mode="standard",
            max_understanding_rounds=1,
            max_planning_rounds=1,
            understanding_quality_threshold=0.6,
            planning_quality_threshold=0.6,
            enable_deep_thinking=False,
            thinking_time_seconds=0.0
        )


def create_interaction_config(
    mode: str = "enhanced", 
    understanding_rounds: int = 5,
    planning_rounds: int = 3,
    quality_threshold: float = 0.8
) -> Configuration:
    """
    åˆ›å»ºè‡ªå®šä¹‰äº¤äº’é…ç½®
    
    Args:
        mode: äº¤äº’æ¨¡å¼ ("standard", "enhanced", "auto")
        understanding_rounds: ç†è§£è½®æ¬¡
        planning_rounds: è§„åˆ’è½®æ¬¡  
        quality_threshold: è´¨é‡é˜ˆå€¼
    
    Returns:
        Configuration: é…ç½®å¯¹è±¡
    """
    return Configuration(
        interaction_mode=mode,
        max_understanding_rounds=understanding_rounds,
        max_planning_rounds=planning_rounds,
        understanding_quality_threshold=quality_threshold,
        planning_quality_threshold=quality_threshold,
        max_plan_iterations=understanding_rounds + planning_rounds,  # å…¼å®¹åŽŸæœ‰å‚æ•°
        enable_deep_thinking=True,
        thinking_time_seconds=1.0 if mode == "enhanced" else 0.5
    )


def load_yaml_config(path: str) -> Dict[str, Any]:
    """Loads a YAML configuration file."""
    try:
        with open(path, "r", encoding="utf-8") as f:
            return yaml.safe_load(f)
    except FileNotFoundError:
        raise ValueError(f"Configuration file not found at: {path}")
    except Exception as e:
        raise ValueError(f"Error loading configuration file at {path}: {e}")
